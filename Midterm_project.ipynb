{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Project\n",
    "\n",
    "\n",
    "You will demonstrate your ability to solve a classification task.\n",
    "\n",
    "The notebook that you submit *should follow the Recipe for Machine Learning* in addition to answering the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "For the student to demonstrate mastery on solving a classification problem and presenting\n",
    "the entire Recipe for Machine Learning process in a notebook.\n",
    "\n",
    "There will be little explicit direction for this task.\n",
    "\n",
    "It is meant to be analagous to a pre-interview task that a potential employer might assign\n",
    "to verify your skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission guidelines\n",
    "\n",
    "**In addition** to showing your mastery, there is one task you must perform to make grading easier.\n",
    "\n",
    "- You will implement the body of a subroutine `MyModel`\n",
    "    - that takes as argument, the name of a CSV file containing the test set\n",
    "    - performs predictions on each example in the test set\n",
    "    - returns an array or predictions with a one-to-one correspondence with the examples in the test set\n",
    "    \n",
    "- You will call the subroutine, passing the name of the test set file that we will supply.\n",
    "\n",
    "In this way, we can get the results of your model by executing a single cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MyModel` has one *required* parameter: `fileName`\n",
    "- you may add additional parameters as you need\n",
    "\n",
    "`MyModel` is where you will perform whatever pre-processing you require, for example\n",
    "- imputing missing values\n",
    "- transformations\n",
    "- whatever else you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the cell **that must appear as the last cell in your notebook**\n",
    "- It points to a test file\n",
    "- Your code must make predictions on this test file\n",
    "- There are *no labels* visible to you in the test file; these are available only to the grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"5th_yr.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file:  ./data/midterm_project/bankruptcy/holdout/5th_yr.csv\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH = \"./data/midterm_project/bankruptcy/holdout\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "testFileName = os.path.join(TEST_PATH, data_file)\n",
    "\n",
    "def MyModel(fileName=None):\n",
    "    print(\"Test file: \", fileName)\n",
    "    \n",
    "    # It should create an array of predictions; we initialize it to the empty array for convenience\n",
    "    predictions = []\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    \n",
    "    \n",
    "    return predictions\n",
    "\n",
    "predicts = MyModel(fileName=testFileName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem\n",
    "\n",
    "You are to predict whether a company will go bankrupt in the following year, based on financial attributes of the company.\n",
    "- Each row of data corresponds to a single company\n",
    "- There are 64 attributes, described in the section below\n",
    "- The last column (`Bankrupt`) is 1 if the company subsequently went bankrupt; 0 if it did not go bankrupt\n",
    "- The first column is a Company Identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe A.1: Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "Here's the code to get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy import stats\n",
    "from statistics import stdev\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "# Note the use of *relative path*; your assignments should all use relative rather than absolute paths\n",
    "DATA_PATH = \"./data/midterm_project/bankruptcy/train\"\n",
    "\n",
    "data = pd.read_csv( os.path.join(DATA_PATH, data_file) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of attributes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "Id Company Identifier \n",
    "X1 net profit / total assets\n",
    "X2 total liabilities / total assets\n",
    "X3 working capital / total assets\n",
    "X4 current assets / short-term liabilities\n",
    "X5 [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\n",
    "X6 retained earnings / total assets\n",
    "X7 EBIT / total assets\n",
    "X8 book value of equity / total liabilities\n",
    "X9 sales / total assets\n",
    "X10 equity / total assets\n",
    "X11 (gross profit + extraordinary items + financial expenses) / total assets\n",
    "X12 gross profit / short-term liabilities\n",
    "X13 (gross profit + depreciation) / sales\n",
    "X14 (gross profit + interest) / total assets\n",
    "X15 (total liabilities * 365) / (gross profit + depreciation)\n",
    "X16 (gross profit + depreciation) / total liabilities\n",
    "X17 total assets / total liabilities\n",
    "X18 gross profit / total assets\n",
    "X19 gross profit / sales\n",
    "X20 (inventory * 365) / sales\n",
    "X21 sales (n) / sales (n-1)\n",
    "X22 profit on operating activities / total assets\n",
    "X23 net profit / sales\n",
    "X24 gross profit (in 3 years) / total assets\n",
    "X25 (equity - share capital) / total assets\n",
    "X26 (net profit + depreciation) / total liabilities\n",
    "X27 profit on operating activities / financial expenses\n",
    "X28 working capital / fixed assets\n",
    "X29 logarithm of total assets\n",
    "X30 (total liabilities - cash) / sales\n",
    "X31 (gross profit + interest) / sales\n",
    "X32 (current liabilities * 365) / cost of products sold\n",
    "X33 operating expenses / short-term liabilities\n",
    "X34 operating expenses / total liabilities\n",
    "X35 profit on sales / total assets\n",
    "X36 total sales / total assets\n",
    "X37 (current assets - inventories) / long-term liabilities\n",
    "X38 constant capital / total assets\n",
    "X39 profit on sales / sales\n",
    "X40 (current assets - inventory - receivables) / short-term liabilities\n",
    "X41 total liabilities / ((profit on operating activities + depreciation) * (12/365))\n",
    "X42 profit on operating activities / sales\n",
    "X43 rotation receivables + inventory turnover in days\n",
    "X44 (receivables * 365) / sales\n",
    "X45 net profit / inventory\n",
    "X46 (current assets - inventory) / short-term liabilities\n",
    "X47 (inventory * 365) / cost of products sold\n",
    "X48 EBITDA (profit on operating activities - depreciation) / total assets\n",
    "X49 EBITDA (profit on operating activities - depreciation) / sales\n",
    "X50 current assets / total liabilities\n",
    "X51 short-term liabilities / total assets\n",
    "X52 (short-term liabilities * 365) / cost of products sold)\n",
    "X53 equity / fixed assets\n",
    "X54 constant capital / fixed assets\n",
    "X55 working capital\n",
    "X56 (sales - cost of products sold) / sales\n",
    "X57 (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\n",
    "X58 total costs /total sales\n",
    "X59 long-term liabilities / equity\n",
    "X60 sales / inventory\n",
    "X61 sales / receivables\n",
    "X62 (short-term liabilities *365) / sales\n",
    "X63 sales / short-term liabilities\n",
    "X64 sales / fixed assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe A.2: Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      "X1          4818 non-null object\n",
      "X2          4818 non-null object\n",
      "X3          4818 non-null object\n",
      "X4          4818 non-null object\n",
      "X5          4818 non-null object\n",
      "X6          4818 non-null object\n",
      "X7          4818 non-null object\n",
      "X8          4818 non-null object\n",
      "X9          4818 non-null float64\n",
      "X10         4818 non-null object\n",
      "X11         4818 non-null object\n",
      "X12         4818 non-null object\n",
      "X13         4818 non-null float64\n",
      "X14         4818 non-null object\n",
      "X15         4818 non-null object\n",
      "X16         4818 non-null object\n",
      "X17         4818 non-null object\n",
      "X18         4818 non-null object\n",
      "X19         4818 non-null float64\n",
      "X20         4818 non-null float64\n",
      "X21         4818 non-null object\n",
      "X22         4818 non-null object\n",
      "X23         4818 non-null float64\n",
      "X24         4818 non-null object\n",
      "X25         4818 non-null object\n",
      "X26         4818 non-null object\n",
      "X27         4818 non-null object\n",
      "X28         4818 non-null object\n",
      "X29         4818 non-null object\n",
      "X30         4818 non-null float64\n",
      "X31         4818 non-null float64\n",
      "X32         4818 non-null object\n",
      "X33         4818 non-null object\n",
      "X34         4818 non-null object\n",
      "X35         4818 non-null object\n",
      "X36         4818 non-null object\n",
      "X37         4818 non-null object\n",
      "X38         4818 non-null object\n",
      "X39         4818 non-null float64\n",
      "X40         4818 non-null object\n",
      "X41         4818 non-null object\n",
      "X42         4818 non-null float64\n",
      "X43         4818 non-null float64\n",
      "X44         4818 non-null float64\n",
      "X45         4818 non-null object\n",
      "X46         4818 non-null object\n",
      "X47         4818 non-null object\n",
      "X48         4818 non-null object\n",
      "X49         4818 non-null float64\n",
      "X50         4818 non-null object\n",
      "X51         4818 non-null object\n",
      "X52         4818 non-null object\n",
      "X53         4818 non-null object\n",
      "X54         4818 non-null object\n",
      "X55         4818 non-null float64\n",
      "X56         4818 non-null float64\n",
      "X57         4818 non-null object\n",
      "X58         4818 non-null float64\n",
      "X59         4818 non-null object\n",
      "X60         4818 non-null object\n",
      "X61         4818 non-null object\n",
      "X62         4818 non-null float64\n",
      "X63         4818 non-null object\n",
      "X64         4818 non-null object\n",
      "Bankrupt    4818 non-null int64\n",
      "Id          4818 non-null int64\n",
      "dtypes: float64(16), int64(2), object(48)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>1.1605</td>\n",
       "      <td>-126.39</td>\n",
       "      <td>0.41355</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>1.2395</td>\n",
       "      <td>1.16500</td>\n",
       "      <td>0.51773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049094</td>\n",
       "      <td>0.85835</td>\n",
       "      <td>0.12322</td>\n",
       "      <td>5.6167</td>\n",
       "      <td>7.4042</td>\n",
       "      <td>164.310</td>\n",
       "      <td>2.2214</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0</td>\n",
       "      <td>4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.023834</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.50839</td>\n",
       "      <td>4.2374</td>\n",
       "      <td>22.034</td>\n",
       "      <td>0.058412</td>\n",
       "      <td>-0.027621</td>\n",
       "      <td>3.6579</td>\n",
       "      <td>0.98183</td>\n",
       "      <td>0.76855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031011</td>\n",
       "      <td>1.01850</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>5.7996</td>\n",
       "      <td>7.7529</td>\n",
       "      <td>26.446</td>\n",
       "      <td>13.802</td>\n",
       "      <td>6.4782</td>\n",
       "      <td>0</td>\n",
       "      <td>3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030515</td>\n",
       "      <td>0.44606</td>\n",
       "      <td>0.19569</td>\n",
       "      <td>1.565</td>\n",
       "      <td>35.766</td>\n",
       "      <td>0.28196</td>\n",
       "      <td>0.039264</td>\n",
       "      <td>0.88456</td>\n",
       "      <td>1.05260</td>\n",
       "      <td>0.39457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077337</td>\n",
       "      <td>0.95006</td>\n",
       "      <td>0.25266</td>\n",
       "      <td>15.049</td>\n",
       "      <td>2.8179</td>\n",
       "      <td>104.730</td>\n",
       "      <td>3.4852</td>\n",
       "      <td>2.6361</td>\n",
       "      <td>0</td>\n",
       "      <td>3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.056366</td>\n",
       "      <td>0.54562</td>\n",
       "      <td>10.68</td>\n",
       "      <td>438.2</td>\n",
       "      <td>0.13649</td>\n",
       "      <td>0.058164</td>\n",
       "      <td>10.853</td>\n",
       "      <td>1.02790</td>\n",
       "      <td>0.61173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085524</td>\n",
       "      <td>0.97282</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0157</td>\n",
       "      <td>7.4626</td>\n",
       "      <td>48.756</td>\n",
       "      <td>7.4863</td>\n",
       "      <td>1.0602</td>\n",
       "      <td>0</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.49712</td>\n",
       "      <td>0.12316</td>\n",
       "      <td>1.3036</td>\n",
       "      <td>-71.398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>1.0116</td>\n",
       "      <td>1.29210</td>\n",
       "      <td>0.50288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.99925</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>3.4819</td>\n",
       "      <td>8.582</td>\n",
       "      <td>114.580</td>\n",
       "      <td>3.1854</td>\n",
       "      <td>2.742</td>\n",
       "      <td>0</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2       X3      X4       X5        X6         X7  \\\n",
       "0   0.025417   0.41769   0.0568  1.1605  -126.39   0.41355   0.025417   \n",
       "1  -0.023834    0.2101  0.50839  4.2374   22.034  0.058412  -0.027621   \n",
       "2   0.030515   0.44606  0.19569   1.565   35.766   0.28196   0.039264   \n",
       "3   0.052318  0.056366  0.54562   10.68    438.2   0.13649   0.058164   \n",
       "4   0.000992   0.49712  0.12316  1.3036  -71.398         0   0.001007   \n",
       "\n",
       "        X8       X9      X10  ...         X57      X58       X59     X60  \\\n",
       "0   1.2395  1.16500  0.51773  ...    0.049094  0.85835   0.12322  5.6167   \n",
       "1   3.6579  0.98183  0.76855  ...   -0.031011  1.01850  0.069047  5.7996   \n",
       "2  0.88456  1.05260  0.39457  ...    0.077337  0.95006   0.25266  15.049   \n",
       "3   10.853  1.02790  0.61173  ...    0.085524  0.97282         0  6.0157   \n",
       "4   1.0116  1.29210  0.50288  ...    0.001974  0.99925  0.019736  3.4819   \n",
       "\n",
       "      X61      X62     X63     X64  Bankrupt    Id  \n",
       "0  7.4042  164.310  2.2214   1.334         0  4510  \n",
       "1  7.7529   26.446  13.802  6.4782         0  3537  \n",
       "2  2.8179  104.730  3.4852  2.6361         0  3920  \n",
       "3  7.4626   48.756  7.4863  1.0602         0  1806  \n",
       "4   8.582  114.580  3.1854   2.742         0  1529  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>0.21199</td>\n",
       "      <td>0.20585</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>1.7941</td>\n",
       "      <td>72.981</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26531</td>\n",
       "      <td>3.8579</td>\n",
       "      <td>0.9842</td>\n",
       "      <td>0.79415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26694</td>\n",
       "      <td>0.73275</td>\n",
       "      <td>0.022101</td>\n",
       "      <td>?</td>\n",
       "      <td>3.5081</td>\n",
       "      <td>66.1710</td>\n",
       "      <td>5.516</td>\n",
       "      <td>1.4476</td>\n",
       "      <td>0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>0.3119</td>\n",
       "      <td>0.09958</td>\n",
       "      <td>0.57936</td>\n",
       "      <td>10.679</td>\n",
       "      <td>245.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.31317</td>\n",
       "      <td>9.0422</td>\n",
       "      <td>1.0516</td>\n",
       "      <td>0.90042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.70705</td>\n",
       "      <td>0.044114</td>\n",
       "      <td>14.018</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>20.7760</td>\n",
       "      <td>17.568</td>\n",
       "      <td>2.9149</td>\n",
       "      <td>0</td>\n",
       "      <td>3963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>-0.029746</td>\n",
       "      <td>0.44898</td>\n",
       "      <td>0.39136</td>\n",
       "      <td>1.9388</td>\n",
       "      <td>7.8073</td>\n",
       "      <td>-0.020006</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>1.2259</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054046</td>\n",
       "      <td>0.99986</td>\n",
       "      <td>0.058336</td>\n",
       "      <td>15.547</td>\n",
       "      <td>8.7022</td>\n",
       "      <td>34.3700</td>\n",
       "      <td>10.62</td>\n",
       "      <td>23.086</td>\n",
       "      <td>0</td>\n",
       "      <td>4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>0.28473</td>\n",
       "      <td>0.079573</td>\n",
       "      <td>0.46261</td>\n",
       "      <td>6.8137</td>\n",
       "      <td>-81.158</td>\n",
       "      <td>-0.79551</td>\n",
       "      <td>0.28473</td>\n",
       "      <td>11.567</td>\n",
       "      <td>6.0718</td>\n",
       "      <td>0.92043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30935</td>\n",
       "      <td>0.19889</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4.7834</td>\n",
       "      <td>76.305</td>\n",
       "      <td>13.263</td>\n",
       "      <td>0</td>\n",
       "      <td>1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>0.12009</td>\n",
       "      <td>0.63072</td>\n",
       "      <td>-0.10501</td>\n",
       "      <td>0.81336</td>\n",
       "      <td>-43.226</td>\n",
       "      <td>-0.17492</td>\n",
       "      <td>0.15424</td>\n",
       "      <td>0.5855</td>\n",
       "      <td>3.1990</td>\n",
       "      <td>0.36928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3252</td>\n",
       "      <td>0.04347</td>\n",
       "      <td>0</td>\n",
       "      <td>12.825</td>\n",
       "      <td>16.441</td>\n",
       "      <td>64.1950</td>\n",
       "      <td>5.6858</td>\n",
       "      <td>5.8982</td>\n",
       "      <td>0</td>\n",
       "      <td>3294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1        X2        X3       X4       X5         X6         X7  \\\n",
       "4813    0.21199   0.20585    0.1417   1.7941   72.981          0    0.26531   \n",
       "4814     0.3119   0.09958   0.57936   10.679   245.98          0    0.31317   \n",
       "4815  -0.029746   0.44898   0.39136   1.9388   7.8073  -0.020006  -0.030561   \n",
       "4816    0.28473  0.079573   0.46261   6.8137  -81.158   -0.79551    0.28473   \n",
       "4817    0.12009   0.63072  -0.10501  0.81336  -43.226   -0.17492    0.15424   \n",
       "\n",
       "          X8      X9      X10  ...         X57      X58       X59     X60  \\\n",
       "4813  3.8579  0.9842  0.79415  ...     0.26694  0.73275  0.022101       ?   \n",
       "4814  9.0422  1.0516  0.90042  ...      0.3464  0.70705  0.044114  14.018   \n",
       "4815  1.2259  1.0001   0.5504  ...   -0.054046  0.99986  0.058336  15.547   \n",
       "4816  11.567  6.0718  0.92043  ...     0.30935  0.19889         0       ?   \n",
       "4817  0.5855  3.1990  0.36928  ...      0.3252  0.04347         0  12.825   \n",
       "\n",
       "         X61      X62     X63     X64  Bankrupt    Id  \n",
       "4813  3.5081  66.1710   5.516  1.4476         0  1985  \n",
       "4814  7.0618  20.7760  17.568  2.9149         0  3963  \n",
       "4815  8.7022  34.3700   10.62  23.086         0  4167  \n",
       "4816    28.5   4.7834  76.305  13.263         0  1579  \n",
       "4817  16.441  64.1950  5.6858  5.8982         0  3294  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No null data in any column.\n",
    "- However, we notice that there are \"?\" in some attributes. We need to replace the text data \"?\" with some numerical data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1           object\n",
       "X2           object\n",
       "X3           object\n",
       "X4           object\n",
       "X5           object\n",
       "X6           object\n",
       "X7           object\n",
       "X8           object\n",
       "X9          float64\n",
       "X10          object\n",
       "X11          object\n",
       "X12          object\n",
       "X13         float64\n",
       "X14          object\n",
       "X15          object\n",
       "X16          object\n",
       "X17          object\n",
       "X18          object\n",
       "X19         float64\n",
       "X20         float64\n",
       "X21          object\n",
       "X22          object\n",
       "X23         float64\n",
       "X24          object\n",
       "X25          object\n",
       "X26          object\n",
       "X27          object\n",
       "X28          object\n",
       "X29          object\n",
       "X30         float64\n",
       "             ...   \n",
       "X37          object\n",
       "X38          object\n",
       "X39         float64\n",
       "X40          object\n",
       "X41          object\n",
       "X42         float64\n",
       "X43         float64\n",
       "X44         float64\n",
       "X45          object\n",
       "X46          object\n",
       "X47          object\n",
       "X48          object\n",
       "X49         float64\n",
       "X50          object\n",
       "X51          object\n",
       "X52          object\n",
       "X53          object\n",
       "X54          object\n",
       "X55         float64\n",
       "X56         float64\n",
       "X57          object\n",
       "X58         float64\n",
       "X59          object\n",
       "X60          object\n",
       "X61          object\n",
       "X62         float64\n",
       "X63          object\n",
       "X64          object\n",
       "Bankrupt      int64\n",
       "Id            int64\n",
       "Length: 66, dtype: object"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Indeed, X1 through X64 should all be float64 rather than object, because those accounting attributes are all floating point numbers with decimal places.\n",
    "- We also need to change data type later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X9</th>\n",
       "      <th>X13</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X23</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X39</th>\n",
       "      <th>X42</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>X49</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X58</th>\n",
       "      <th>X62</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4.818000e+03</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "      <td>4818.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.579277</td>\n",
       "      <td>0.452284</td>\n",
       "      <td>-0.082028</td>\n",
       "      <td>57.002168</td>\n",
       "      <td>-0.090357</td>\n",
       "      <td>0.691991</td>\n",
       "      <td>-0.068612</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>-0.014902</td>\n",
       "      <td>155.612840</td>\n",
       "      <td>98.610765</td>\n",
       "      <td>-0.072253</td>\n",
       "      <td>1.074023e+04</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.959585</td>\n",
       "      <td>177.494445</td>\n",
       "      <td>0.063927</td>\n",
       "      <td>3499.858032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.342723</td>\n",
       "      <td>34.196231</td>\n",
       "      <td>5.754879</td>\n",
       "      <td>182.018911</td>\n",
       "      <td>5.725258</td>\n",
       "      <td>11.217691</td>\n",
       "      <td>5.748967</td>\n",
       "      <td>0.756891</td>\n",
       "      <td>2.617310</td>\n",
       "      <td>795.989622</td>\n",
       "      <td>725.594072</td>\n",
       "      <td>2.638443</td>\n",
       "      <td>8.284685e+04</td>\n",
       "      <td>0.755462</td>\n",
       "      <td>0.932427</td>\n",
       "      <td>2279.713700</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>1392.049260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>-310.340000</td>\n",
       "      <td>-310.800000</td>\n",
       "      <td>-29.340000</td>\n",
       "      <td>-310.890000</td>\n",
       "      <td>-23.060000</td>\n",
       "      <td>-310.800000</td>\n",
       "      <td>-47.047000</td>\n",
       "      <td>-143.520000</td>\n",
       "      <td>-3975.600000</td>\n",
       "      <td>-3946.200000</td>\n",
       "      <td>-144.800000</td>\n",
       "      <td>-1.118500e+06</td>\n",
       "      <td>-46.788000</td>\n",
       "      <td>-0.085920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.015600</td>\n",
       "      <td>0.024954</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>18.537750</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.085560</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>76.214500</td>\n",
       "      <td>39.050250</td>\n",
       "      <td>-0.022447</td>\n",
       "      <td>9.771450e+01</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.876940</td>\n",
       "      <td>45.065750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2296.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.140500</td>\n",
       "      <td>0.067723</td>\n",
       "      <td>0.035307</td>\n",
       "      <td>38.623000</td>\n",
       "      <td>0.030074</td>\n",
       "      <td>0.225955</td>\n",
       "      <td>0.042826</td>\n",
       "      <td>0.040252</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>106.670000</td>\n",
       "      <td>59.014000</td>\n",
       "      <td>0.012481</td>\n",
       "      <td>1.829500e+03</td>\n",
       "      <td>0.053663</td>\n",
       "      <td>0.950825</td>\n",
       "      <td>73.879500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.814050</td>\n",
       "      <td>0.134847</td>\n",
       "      <td>0.088287</td>\n",
       "      <td>66.850750</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.406145</td>\n",
       "      <td>0.098331</td>\n",
       "      <td>0.091854</td>\n",
       "      <td>0.090831</td>\n",
       "      <td>149.365000</td>\n",
       "      <td>86.087750</td>\n",
       "      <td>0.060499</td>\n",
       "      <td>7.786950e+03</td>\n",
       "      <td>0.124030</td>\n",
       "      <td>0.990358</td>\n",
       "      <td>118.597500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4704.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37.807000</td>\n",
       "      <td>2340.200000</td>\n",
       "      <td>77.244000</td>\n",
       "      <td>9928.500000</td>\n",
       "      <td>77.244000</td>\n",
       "      <td>656.450000</td>\n",
       "      <td>77.244000</td>\n",
       "      <td>2.901100</td>\n",
       "      <td>40.386000</td>\n",
       "      <td>40515.000000</td>\n",
       "      <td>40515.000000</td>\n",
       "      <td>16.866000</td>\n",
       "      <td>4.212200e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.788000</td>\n",
       "      <td>127450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5909.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X9          X13          X19          X20          X23  \\\n",
       "count  4818.000000  4818.000000  4818.000000  4818.000000  4818.000000   \n",
       "mean      1.579277     0.452284    -0.082028    57.002168    -0.090357   \n",
       "std       1.342723    34.196231     5.754879   182.018911     5.725258   \n",
       "min       0.000191  -310.340000  -310.800000   -29.340000  -310.890000   \n",
       "25%       1.015600     0.024954     0.004368    18.537750     0.002728   \n",
       "50%       1.140500     0.067723     0.035307    38.623000     0.030074   \n",
       "75%       1.814050     0.134847     0.088287    66.850750     0.075800   \n",
       "max      37.807000  2340.200000    77.244000  9928.500000    77.244000   \n",
       "\n",
       "               X30          X31          X39          X42           X43  \\\n",
       "count  4818.000000  4818.000000  4818.000000  4818.000000   4818.000000   \n",
       "mean      0.691991    -0.068612     0.019158    -0.014902    155.612840   \n",
       "std      11.217691     5.748967     0.756891     2.617310    795.989622   \n",
       "min     -23.060000  -310.800000   -47.047000  -143.520000  -3975.600000   \n",
       "25%       0.085560     0.007006     0.005536     0.000687     76.214500   \n",
       "50%       0.225955     0.042826     0.040252     0.040963    106.670000   \n",
       "75%       0.406145     0.098331     0.091854     0.090831    149.365000   \n",
       "max     656.450000    77.244000     2.901100    40.386000  40515.000000   \n",
       "\n",
       "                X44          X49           X55          X56          X58  \\\n",
       "count   4818.000000  4818.000000  4.818000e+03  4818.000000  4818.000000   \n",
       "mean      98.610765    -0.072253  1.074023e+04     0.056109     0.959585   \n",
       "std      725.594072     2.638443  8.284685e+04     0.755462     0.932427   \n",
       "min    -3946.200000  -144.800000 -1.118500e+06   -46.788000    -0.085920   \n",
       "25%       39.050250    -0.022447  9.771450e+01     0.011478     0.876940   \n",
       "50%       59.014000     0.012481  1.829500e+03     0.053663     0.950825   \n",
       "75%       86.087750     0.060499  7.786950e+03     0.124030     0.990358   \n",
       "max    40515.000000    16.866000  4.212200e+06     1.000000    47.788000   \n",
       "\n",
       "                 X62     Bankrupt           Id  \n",
       "count    4818.000000  4818.000000  4818.000000  \n",
       "mean      177.494445     0.063927  3499.858032  \n",
       "std      2279.713700     0.244648  1392.049260  \n",
       "min         0.000000     0.000000  1071.000000  \n",
       "25%        45.065750     0.000000  2296.250000  \n",
       "50%        73.879500     0.000000  3500.500000  \n",
       "75%       118.597500     0.000000  4704.750000  \n",
       "max    127450.000000     1.000000  5909.000000  "
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4818, 66)"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe A.3: Define a performance measure\n",
    "- Let's use Accuracy as a performance measure. We also check recall, precision, specificity & false positive.\n",
    "- Indeed, we'll find out later that accuracy is not a very good performance measure here. We will instead use F1 score as a performance measure after resampling in the extra credit part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe A.4: Create a test set\n",
    "\n",
    "- \"holdout\" **does not** have targets (Column \"Bankrupt\") associated with it, so we can't use data in \"holdout\" as examples on which to evaluate the Performance Metric.\n",
    "\n",
    "- So, let's further split \"data\" into X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(columns = ['Bankrupt']), data['Bankrupt'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3854, 65), (964, 65), (3854,), (964,))"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the shape \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.044757</td>\n",
       "      <td>0.49112</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>-10.922</td>\n",
       "      <td>0.13414</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>0.97991</td>\n",
       "      <td>1.0891</td>\n",
       "      <td>0.48125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081838</td>\n",
       "      <td>0.093001</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>0.72595</td>\n",
       "      <td>39.822</td>\n",
       "      <td>11.499</td>\n",
       "      <td>109.670</td>\n",
       "      <td>3.3281</td>\n",
       "      <td>0.55093</td>\n",
       "      <td>5691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>0.00969</td>\n",
       "      <td>0.60158</td>\n",
       "      <td>0.21247</td>\n",
       "      <td>2.6707</td>\n",
       "      <td>42.71</td>\n",
       "      <td>0.035651</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.62063</td>\n",
       "      <td>1.0472</td>\n",
       "      <td>0.37336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>0.025954</td>\n",
       "      <td>0.95497</td>\n",
       "      <td>1.2706</td>\n",
       "      <td>10.178</td>\n",
       "      <td>4.8416</td>\n",
       "      <td>45.180</td>\n",
       "      <td>8.0788</td>\n",
       "      <td>1.5559</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>0.014994</td>\n",
       "      <td>0.73291</td>\n",
       "      <td>0.34177</td>\n",
       "      <td>2.1422</td>\n",
       "      <td>-74.761</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.36443</td>\n",
       "      <td>1.1278</td>\n",
       "      <td>0.26709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136290</td>\n",
       "      <td>0.056139</td>\n",
       "      <td>0.99686</td>\n",
       "      <td>1.2507</td>\n",
       "      <td>16.314</td>\n",
       "      <td>13.388</td>\n",
       "      <td>96.841</td>\n",
       "      <td>3.7691</td>\n",
       "      <td>3.1415</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>0.351</td>\n",
       "      <td>0.25999</td>\n",
       "      <td>0.672</td>\n",
       "      <td>4.0607</td>\n",
       "      <td>70.293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43429</td>\n",
       "      <td>2.8463</td>\n",
       "      <td>2.0269</td>\n",
       "      <td>0.74001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209330</td>\n",
       "      <td>0.47432</td>\n",
       "      <td>0.79193</td>\n",
       "      <td>0</td>\n",
       "      <td>22.838</td>\n",
       "      <td>3.9075</td>\n",
       "      <td>39.539</td>\n",
       "      <td>9.2315</td>\n",
       "      <td>18.69</td>\n",
       "      <td>3715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0.030069</td>\n",
       "      <td>0.58084</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>1.0101</td>\n",
       "      <td>-9.063</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03983</td>\n",
       "      <td>0.72163</td>\n",
       "      <td>4.6379</td>\n",
       "      <td>0.41916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>0.99141</td>\n",
       "      <td>0.22429</td>\n",
       "      <td>44.595</td>\n",
       "      <td>16.789</td>\n",
       "      <td>38.151</td>\n",
       "      <td>9.5672</td>\n",
       "      <td>9.0879</td>\n",
       "      <td>4257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1       X2        X3      X4       X5        X6        X7  \\\n",
       "220   0.044757  0.49112  0.001948  1.0137  -10.922   0.13414  0.050963   \n",
       "1361   0.00969  0.60158   0.21247  2.6707    42.71  0.035651  0.012172   \n",
       "1010  0.014994  0.73291   0.34177  2.1422  -74.761  0.002097  0.003592   \n",
       "2952     0.351  0.25999     0.672  4.0607   70.293         0   0.43429   \n",
       "2135  0.030069  0.58084  0.004893  1.0101   -9.063         0   0.03983   \n",
       "\n",
       "           X8      X9      X10  ...        X56       X57      X58      X59  \\\n",
       "220   0.97991  1.0891  0.48125  ...   0.081838  0.093001  0.91816  0.72595   \n",
       "1361  0.62063  1.0472  0.37336  ...   0.045033  0.025954  0.95497   1.2706   \n",
       "1010  0.36443  1.1278  0.26709  ...   0.136290  0.056139  0.99686   1.2507   \n",
       "2952   2.8463  2.0269  0.74001  ...   0.209330   0.47432  0.79193        0   \n",
       "2135  0.72163  4.6379  0.41916  ...   0.009166  0.071737  0.99141  0.22429   \n",
       "\n",
       "         X60     X61      X62     X63      X64    Id  \n",
       "220   39.822  11.499  109.670  3.3281  0.55093  5691  \n",
       "1361  10.178  4.8416   45.180  8.0788   1.5559  1101  \n",
       "1010  16.314  13.388   96.841  3.7691   3.1415  4461  \n",
       "2952  22.838  3.9075   39.539  9.2315    18.69  3715  \n",
       "2135  44.595  16.789   38.151  9.5672   9.0879  4257  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the head \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.67203</td>\n",
       "      <td>0.14227</td>\n",
       "      <td>1.2156</td>\n",
       "      <td>-49.408</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.48075</td>\n",
       "      <td>1.00740</td>\n",
       "      <td>0.32308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.99269</td>\n",
       "      <td>0.037272</td>\n",
       "      <td>12.302</td>\n",
       "      <td>4.0442</td>\n",
       "      <td>140.440</td>\n",
       "      <td>2.5991</td>\n",
       "      <td>8.6745</td>\n",
       "      <td>3119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>0.13963</td>\n",
       "      <td>0.25081</td>\n",
       "      <td>0.25848</td>\n",
       "      <td>2.2523</td>\n",
       "      <td>31.714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.18239</td>\n",
       "      <td>2.9871</td>\n",
       "      <td>1.54600</td>\n",
       "      <td>0.74919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>0.18637</td>\n",
       "      <td>0.88279</td>\n",
       "      <td>0.044616</td>\n",
       "      <td>11.279</td>\n",
       "      <td>5.1096</td>\n",
       "      <td>48.732</td>\n",
       "      <td>7.4899</td>\n",
       "      <td>2.8891</td>\n",
       "      <td>3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0.1476</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>0.46987</td>\n",
       "      <td>6.4957</td>\n",
       "      <td>59.981</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.18156</td>\n",
       "      <td>9.2184</td>\n",
       "      <td>1.44620</td>\n",
       "      <td>0.90214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123660</td>\n",
       "      <td>0.16362</td>\n",
       "      <td>0.87543</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5314</td>\n",
       "      <td>6.8732</td>\n",
       "      <td>21.578</td>\n",
       "      <td>16.916</td>\n",
       "      <td>3.2526</td>\n",
       "      <td>5358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.032618</td>\n",
       "      <td>0.74375</td>\n",
       "      <td>0.052153</td>\n",
       "      <td>1.1584</td>\n",
       "      <td>-49.698</td>\n",
       "      <td>0.11127</td>\n",
       "      <td>0.044782</td>\n",
       "      <td>0.33163</td>\n",
       "      <td>1.05450</td>\n",
       "      <td>0.24665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051681</td>\n",
       "      <td>0.13224</td>\n",
       "      <td>0.94832</td>\n",
       "      <td>1.6806</td>\n",
       "      <td>6.5521</td>\n",
       "      <td>33.065</td>\n",
       "      <td>59.524</td>\n",
       "      <td>6.1319</td>\n",
       "      <td>3.2633</td>\n",
       "      <td>3134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.022155</td>\n",
       "      <td>0.54875</td>\n",
       "      <td>0.54093</td>\n",
       "      <td>2.8668</td>\n",
       "      <td>14.402</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022155</td>\n",
       "      <td>0.82231</td>\n",
       "      <td>0.61232</td>\n",
       "      <td>0.45125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.049097</td>\n",
       "      <td>0.96466</td>\n",
       "      <td>0.55833</td>\n",
       "      <td>1.1969</td>\n",
       "      <td>2.5829</td>\n",
       "      <td>172.720</td>\n",
       "      <td>2.1132</td>\n",
       "      <td>3.6164</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3      X4       X5        X6        X7  \\\n",
       "4340  0.001173   0.67203   0.14227  1.2156  -49.408  0.016824  0.001271   \n",
       "1221   0.13963   0.25081   0.25848  2.2523   31.714         0   0.18239   \n",
       "2083    0.1476  0.097863   0.46987  6.4957   59.981  0.003564   0.18156   \n",
       "1044  0.032618   0.74375  0.052153  1.1584  -49.698   0.11127  0.044782   \n",
       "2555  0.022155   0.54875   0.54093  2.8668   14.402         0  0.022155   \n",
       "\n",
       "           X8       X9      X10  ...        X56       X57      X58       X59  \\\n",
       "4340  0.48075  1.00740  0.32308  ...   0.007312  0.003629  0.99269  0.037272   \n",
       "1221   2.9871  1.54600  0.74919  ...   0.124670   0.18637  0.88279  0.044616   \n",
       "2083   9.2184  1.44620  0.90214  ...   0.123660   0.16362  0.87543         0   \n",
       "1044  0.33163  1.05450  0.24665  ...   0.051681   0.13224  0.94832    1.6806   \n",
       "2555  0.82231  0.61232  0.45125  ...   0.066985  0.049097  0.96466   0.55833   \n",
       "\n",
       "         X60     X61      X62     X63     X64    Id  \n",
       "4340  12.302  4.0442  140.440  2.5991  8.6745  3119  \n",
       "1221  11.279  5.1096   48.732  7.4899  2.8891  3687  \n",
       "2083  5.5314  6.8732   21.578  16.916  3.2526  5358  \n",
       "1044  6.5521  33.065   59.524  6.1319  3.2633  3134  \n",
       "2555  1.1969  2.5829  172.720  2.1132  3.6164  4500  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220     0\n",
       "1361    0\n",
       "1010    0\n",
       "2952    0\n",
       "2135    0\n",
       "Name: Bankrupt, dtype: int64"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4340    0\n",
       "1221    0\n",
       "2083    0\n",
       "1044    0\n",
       "2555    0\n",
       "Name: Bankrupt, dtype: int64"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe B: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot X_train histogram for X1 through X64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = X_train.hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe C.1: Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Replace all \"?\" in X_train & X_test with NaN, then change data type from object to float64 \n",
    "- keep \"Id\" as int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train['X1']).count('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.replace('?', np.NaN)\n",
    "X_test = X_test.replace('?', np.NaN)\n",
    "list(X_train['X1']).count('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1        2\n",
       "X2        2\n",
       "X3        2\n",
       "X4       10\n",
       "X5        9\n",
       "X6        2\n",
       "X7        2\n",
       "X8       10\n",
       "X9        0\n",
       "X10       2\n",
       "X11       2\n",
       "X12      10\n",
       "X13       0\n",
       "X14       2\n",
       "X15       4\n",
       "X16      10\n",
       "X17      10\n",
       "X18       2\n",
       "X19       0\n",
       "X20       0\n",
       "X21      59\n",
       "X22       2\n",
       "X23       0\n",
       "X24      94\n",
       "X25       2\n",
       "X26      10\n",
       "X27     241\n",
       "X28      66\n",
       "X29       2\n",
       "X30       0\n",
       "       ... \n",
       "X36       2\n",
       "X37    1665\n",
       "X38       2\n",
       "X39       0\n",
       "X40      10\n",
       "X41      48\n",
       "X42       0\n",
       "X43       0\n",
       "X44       0\n",
       "X45     177\n",
       "X46      10\n",
       "X47      28\n",
       "X48       2\n",
       "X49       0\n",
       "X50      10\n",
       "X51       2\n",
       "X52      28\n",
       "X53      66\n",
       "X54      66\n",
       "X55       0\n",
       "X56       0\n",
       "X57       2\n",
       "X58       0\n",
       "X59       2\n",
       "X60     177\n",
       "X61       9\n",
       "X62       0\n",
       "X63      10\n",
       "X64      66\n",
       "Id        0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype('float64')\n",
    "X_train['Id'] = X_train['Id'].astype('int64')\n",
    "\n",
    "X_test = X_test.astype('float64')\n",
    "X_test['Id'] = X_test['Id'].astype('int64')\n",
    "\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1       0\n",
       "X2       0\n",
       "X3       0\n",
       "X4       5\n",
       "X5       1\n",
       "X6       0\n",
       "X7       0\n",
       "X8       4\n",
       "X9       0\n",
       "X10      0\n",
       "X11      0\n",
       "X12      5\n",
       "X13      0\n",
       "X14      0\n",
       "X15      2\n",
       "X16      4\n",
       "X17      4\n",
       "X18      0\n",
       "X19      0\n",
       "X20      0\n",
       "X21     15\n",
       "X22      0\n",
       "X23      0\n",
       "X24     22\n",
       "X25      0\n",
       "X26      4\n",
       "X27     64\n",
       "X28     17\n",
       "X29      0\n",
       "X30      0\n",
       "      ... \n",
       "X36      0\n",
       "X37    403\n",
       "X38      0\n",
       "X39      0\n",
       "X40      5\n",
       "X41     14\n",
       "X42      0\n",
       "X43      0\n",
       "X44      0\n",
       "X45     43\n",
       "X46      5\n",
       "X47      3\n",
       "X48      0\n",
       "X49      0\n",
       "X50      4\n",
       "X51      0\n",
       "X52      4\n",
       "X53     17\n",
       "X54     17\n",
       "X55      0\n",
       "X56      0\n",
       "X57      0\n",
       "X58      0\n",
       "X59      0\n",
       "X60     43\n",
       "X61      3\n",
       "X62      0\n",
       "X63      5\n",
       "X64     17\n",
       "Id       0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since \"Bankrupt\" data type is int64, there's no \"?\" in its column. Thus, we don't need to alter y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3854, 65), (3854,))"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Replace NaN in X_train & X_test with median\n",
    "- Since the function for each X is given, I was initially trying to derive the exact number for NaN using the known X's of each company. However, I realized that many X's associated with NaN are also missing. \n",
    "- Since the \"exact\" way doesn't work, let's use median to fill NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1     0\n",
       "X2     0\n",
       "X3     0\n",
       "X4     0\n",
       "X5     0\n",
       "X6     0\n",
       "X7     0\n",
       "X8     0\n",
       "X9     0\n",
       "X10    0\n",
       "X11    0\n",
       "X12    0\n",
       "X13    0\n",
       "X14    0\n",
       "X15    0\n",
       "X16    0\n",
       "X17    0\n",
       "X18    0\n",
       "X19    0\n",
       "X20    0\n",
       "X21    0\n",
       "X22    0\n",
       "X23    0\n",
       "X24    0\n",
       "X25    0\n",
       "X26    0\n",
       "X27    0\n",
       "X28    0\n",
       "X29    0\n",
       "X30    0\n",
       "      ..\n",
       "X36    0\n",
       "X37    0\n",
       "X38    0\n",
       "X39    0\n",
       "X40    0\n",
       "X41    0\n",
       "X42    0\n",
       "X43    0\n",
       "X44    0\n",
       "X45    0\n",
       "X46    0\n",
       "X47    0\n",
       "X48    0\n",
       "X49    0\n",
       "X50    0\n",
       "X51    0\n",
       "X52    0\n",
       "X53    0\n",
       "X54    0\n",
       "X55    0\n",
       "X56    0\n",
       "X57    0\n",
       "X58    0\n",
       "X59    0\n",
       "X60    0\n",
       "X61    0\n",
       "X62    0\n",
       "X63    0\n",
       "X64    0\n",
       "Id     0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_median = X_train.median()\n",
    "\n",
    "X_train.fillna(X_train_median, inplace = True)\n",
    "X_test.fillna(X_train_median, inplace = True)\n",
    "\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3854, 65), (3854,))"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.044757</td>\n",
       "      <td>0.49112</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>-10.922</td>\n",
       "      <td>0.134140</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>0.97991</td>\n",
       "      <td>1.0891</td>\n",
       "      <td>0.48125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081838</td>\n",
       "      <td>0.093001</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>0.72595</td>\n",
       "      <td>39.822</td>\n",
       "      <td>11.4990</td>\n",
       "      <td>109.670</td>\n",
       "      <td>3.3281</td>\n",
       "      <td>0.55093</td>\n",
       "      <td>5691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.60158</td>\n",
       "      <td>0.212470</td>\n",
       "      <td>2.6707</td>\n",
       "      <td>42.710</td>\n",
       "      <td>0.035651</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.62063</td>\n",
       "      <td>1.0472</td>\n",
       "      <td>0.37336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>0.025954</td>\n",
       "      <td>0.95497</td>\n",
       "      <td>1.27060</td>\n",
       "      <td>10.178</td>\n",
       "      <td>4.8416</td>\n",
       "      <td>45.180</td>\n",
       "      <td>8.0788</td>\n",
       "      <td>1.55590</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>0.014994</td>\n",
       "      <td>0.73291</td>\n",
       "      <td>0.341770</td>\n",
       "      <td>2.1422</td>\n",
       "      <td>-74.761</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.36443</td>\n",
       "      <td>1.1278</td>\n",
       "      <td>0.26709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136290</td>\n",
       "      <td>0.056139</td>\n",
       "      <td>0.99686</td>\n",
       "      <td>1.25070</td>\n",
       "      <td>16.314</td>\n",
       "      <td>13.3880</td>\n",
       "      <td>96.841</td>\n",
       "      <td>3.7691</td>\n",
       "      <td>3.14150</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>0.351000</td>\n",
       "      <td>0.25999</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>4.0607</td>\n",
       "      <td>70.293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434290</td>\n",
       "      <td>2.84630</td>\n",
       "      <td>2.0269</td>\n",
       "      <td>0.74001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209330</td>\n",
       "      <td>0.474320</td>\n",
       "      <td>0.79193</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>22.838</td>\n",
       "      <td>3.9075</td>\n",
       "      <td>39.539</td>\n",
       "      <td>9.2315</td>\n",
       "      <td>18.69000</td>\n",
       "      <td>3715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0.030069</td>\n",
       "      <td>0.58084</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>1.0101</td>\n",
       "      <td>-9.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039830</td>\n",
       "      <td>0.72163</td>\n",
       "      <td>4.6379</td>\n",
       "      <td>0.41916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>0.99141</td>\n",
       "      <td>0.22429</td>\n",
       "      <td>44.595</td>\n",
       "      <td>16.7890</td>\n",
       "      <td>38.151</td>\n",
       "      <td>9.5672</td>\n",
       "      <td>9.08790</td>\n",
       "      <td>4257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1       X2        X3      X4      X5        X6        X7  \\\n",
       "220   0.044757  0.49112  0.001948  1.0137 -10.922  0.134140  0.050963   \n",
       "1361  0.009690  0.60158  0.212470  2.6707  42.710  0.035651  0.012172   \n",
       "1010  0.014994  0.73291  0.341770  2.1422 -74.761  0.002097  0.003592   \n",
       "2952  0.351000  0.25999  0.672000  4.0607  70.293  0.000000  0.434290   \n",
       "2135  0.030069  0.58084  0.004893  1.0101  -9.063  0.000000  0.039830   \n",
       "\n",
       "           X8      X9      X10  ...        X56       X57      X58      X59  \\\n",
       "220   0.97991  1.0891  0.48125  ...   0.081838  0.093001  0.91816  0.72595   \n",
       "1361  0.62063  1.0472  0.37336  ...   0.045033  0.025954  0.95497  1.27060   \n",
       "1010  0.36443  1.1278  0.26709  ...   0.136290  0.056139  0.99686  1.25070   \n",
       "2952  2.84630  2.0269  0.74001  ...   0.209330  0.474320  0.79193  0.00000   \n",
       "2135  0.72163  4.6379  0.41916  ...   0.009166  0.071737  0.99141  0.22429   \n",
       "\n",
       "         X60      X61      X62     X63       X64    Id  \n",
       "220   39.822  11.4990  109.670  3.3281   0.55093  5691  \n",
       "1361  10.178   4.8416   45.180  8.0788   1.55590  1101  \n",
       "1010  16.314  13.3880   96.841  3.7691   3.14150  4461  \n",
       "2952  22.838   3.9075   39.539  9.2315  18.69000  3715  \n",
       "2135  44.595  16.7890   38.151  9.5672   9.08790  4257  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Set \"Id\" as index for X_train & X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>0.044757</td>\n",
       "      <td>0.49112</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>-10.922</td>\n",
       "      <td>0.134140</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>0.97991</td>\n",
       "      <td>1.0891</td>\n",
       "      <td>0.48125</td>\n",
       "      <td>...</td>\n",
       "      <td>6981.500</td>\n",
       "      <td>0.081838</td>\n",
       "      <td>0.093001</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>0.72595</td>\n",
       "      <td>39.822</td>\n",
       "      <td>11.4990</td>\n",
       "      <td>109.670</td>\n",
       "      <td>3.3281</td>\n",
       "      <td>0.55093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.60158</td>\n",
       "      <td>0.212470</td>\n",
       "      <td>2.6707</td>\n",
       "      <td>42.710</td>\n",
       "      <td>0.035651</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.62063</td>\n",
       "      <td>1.0472</td>\n",
       "      <td>0.37336</td>\n",
       "      <td>...</td>\n",
       "      <td>46802.000</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>0.025954</td>\n",
       "      <td>0.95497</td>\n",
       "      <td>1.27060</td>\n",
       "      <td>10.178</td>\n",
       "      <td>4.8416</td>\n",
       "      <td>45.180</td>\n",
       "      <td>8.0788</td>\n",
       "      <td>1.55590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0.014994</td>\n",
       "      <td>0.73291</td>\n",
       "      <td>0.341770</td>\n",
       "      <td>2.1422</td>\n",
       "      <td>-74.761</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.36443</td>\n",
       "      <td>1.1278</td>\n",
       "      <td>0.26709</td>\n",
       "      <td>...</td>\n",
       "      <td>11760.000</td>\n",
       "      <td>0.136290</td>\n",
       "      <td>0.056139</td>\n",
       "      <td>0.99686</td>\n",
       "      <td>1.25070</td>\n",
       "      <td>16.314</td>\n",
       "      <td>13.3880</td>\n",
       "      <td>96.841</td>\n",
       "      <td>3.7691</td>\n",
       "      <td>3.14150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>0.351000</td>\n",
       "      <td>0.25999</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>4.0607</td>\n",
       "      <td>70.293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434290</td>\n",
       "      <td>2.84630</td>\n",
       "      <td>2.0269</td>\n",
       "      <td>0.74001</td>\n",
       "      <td>...</td>\n",
       "      <td>3206.200</td>\n",
       "      <td>0.209330</td>\n",
       "      <td>0.474320</td>\n",
       "      <td>0.79193</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>22.838</td>\n",
       "      <td>3.9075</td>\n",
       "      <td>39.539</td>\n",
       "      <td>9.2315</td>\n",
       "      <td>18.69000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>0.030069</td>\n",
       "      <td>0.58084</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>1.0101</td>\n",
       "      <td>-9.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039830</td>\n",
       "      <td>0.72163</td>\n",
       "      <td>4.6379</td>\n",
       "      <td>0.41916</td>\n",
       "      <td>...</td>\n",
       "      <td>15.613</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>0.99141</td>\n",
       "      <td>0.22429</td>\n",
       "      <td>44.595</td>\n",
       "      <td>16.7890</td>\n",
       "      <td>38.151</td>\n",
       "      <td>9.5672</td>\n",
       "      <td>9.08790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1       X2        X3      X4      X5        X6        X7  \\\n",
       "Id                                                                      \n",
       "5691  0.044757  0.49112  0.001948  1.0137 -10.922  0.134140  0.050963   \n",
       "1101  0.009690  0.60158  0.212470  2.6707  42.710  0.035651  0.012172   \n",
       "4461  0.014994  0.73291  0.341770  2.1422 -74.761  0.002097  0.003592   \n",
       "3715  0.351000  0.25999  0.672000  4.0607  70.293  0.000000  0.434290   \n",
       "4257  0.030069  0.58084  0.004893  1.0101  -9.063  0.000000  0.039830   \n",
       "\n",
       "           X8      X9      X10    ...           X55       X56       X57  \\\n",
       "Id                                ...                                     \n",
       "5691  0.97991  1.0891  0.48125    ...      6981.500  0.081838  0.093001   \n",
       "1101  0.62063  1.0472  0.37336    ...     46802.000  0.045033  0.025954   \n",
       "4461  0.36443  1.1278  0.26709    ...     11760.000  0.136290  0.056139   \n",
       "3715  2.84630  2.0269  0.74001    ...      3206.200  0.209330  0.474320   \n",
       "4257  0.72163  4.6379  0.41916    ...        15.613  0.009166  0.071737   \n",
       "\n",
       "          X58      X59     X60      X61      X62     X63       X64  \n",
       "Id                                                                  \n",
       "5691  0.91816  0.72595  39.822  11.4990  109.670  3.3281   0.55093  \n",
       "1101  0.95497  1.27060  10.178   4.8416   45.180  8.0788   1.55590  \n",
       "4461  0.99686  1.25070  16.314  13.3880   96.841  3.7691   3.14150  \n",
       "3715  0.79193  0.00000  22.838   3.9075   39.539  9.2315  18.69000  \n",
       "4257  0.99141  0.22429  44.595  16.7890   38.151  9.5672   9.08790  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.set_index('Id', inplace=True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.672030</td>\n",
       "      <td>0.142270</td>\n",
       "      <td>1.2156</td>\n",
       "      <td>-49.408</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.48075</td>\n",
       "      <td>1.00740</td>\n",
       "      <td>0.32308</td>\n",
       "      <td>...</td>\n",
       "      <td>19985.0</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.99269</td>\n",
       "      <td>0.037272</td>\n",
       "      <td>12.3020</td>\n",
       "      <td>4.0442</td>\n",
       "      <td>140.440</td>\n",
       "      <td>2.5991</td>\n",
       "      <td>8.6745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>0.139630</td>\n",
       "      <td>0.250810</td>\n",
       "      <td>0.258480</td>\n",
       "      <td>2.2523</td>\n",
       "      <td>31.714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182390</td>\n",
       "      <td>2.98710</td>\n",
       "      <td>1.54600</td>\n",
       "      <td>0.74919</td>\n",
       "      <td>...</td>\n",
       "      <td>2443.9</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>0.186370</td>\n",
       "      <td>0.88279</td>\n",
       "      <td>0.044616</td>\n",
       "      <td>11.2790</td>\n",
       "      <td>5.1096</td>\n",
       "      <td>48.732</td>\n",
       "      <td>7.4899</td>\n",
       "      <td>2.8891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>0.469870</td>\n",
       "      <td>6.4957</td>\n",
       "      <td>59.981</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.181560</td>\n",
       "      <td>9.21840</td>\n",
       "      <td>1.44620</td>\n",
       "      <td>0.90214</td>\n",
       "      <td>...</td>\n",
       "      <td>19041.0</td>\n",
       "      <td>0.123660</td>\n",
       "      <td>0.163620</td>\n",
       "      <td>0.87543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.5314</td>\n",
       "      <td>6.8732</td>\n",
       "      <td>21.578</td>\n",
       "      <td>16.9160</td>\n",
       "      <td>3.2526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>0.032618</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.052153</td>\n",
       "      <td>1.1584</td>\n",
       "      <td>-49.698</td>\n",
       "      <td>0.111270</td>\n",
       "      <td>0.044782</td>\n",
       "      <td>0.33163</td>\n",
       "      <td>1.05450</td>\n",
       "      <td>0.24665</td>\n",
       "      <td>...</td>\n",
       "      <td>4087.9</td>\n",
       "      <td>0.051681</td>\n",
       "      <td>0.132240</td>\n",
       "      <td>0.94832</td>\n",
       "      <td>1.680600</td>\n",
       "      <td>6.5521</td>\n",
       "      <td>33.0650</td>\n",
       "      <td>59.524</td>\n",
       "      <td>6.1319</td>\n",
       "      <td>3.2633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>0.022155</td>\n",
       "      <td>0.548750</td>\n",
       "      <td>0.540930</td>\n",
       "      <td>2.8668</td>\n",
       "      <td>14.402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022155</td>\n",
       "      <td>0.82231</td>\n",
       "      <td>0.61232</td>\n",
       "      <td>0.45125</td>\n",
       "      <td>...</td>\n",
       "      <td>4408.8</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.049097</td>\n",
       "      <td>0.96466</td>\n",
       "      <td>0.558330</td>\n",
       "      <td>1.1969</td>\n",
       "      <td>2.5829</td>\n",
       "      <td>172.720</td>\n",
       "      <td>2.1132</td>\n",
       "      <td>3.6164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3      X4      X5        X6        X7  \\\n",
       "Id                                                                       \n",
       "3119  0.001173  0.672030  0.142270  1.2156 -49.408  0.016824  0.001271   \n",
       "3687  0.139630  0.250810  0.258480  2.2523  31.714  0.000000  0.182390   \n",
       "5358  0.147600  0.097863  0.469870  6.4957  59.981  0.003564  0.181560   \n",
       "3134  0.032618  0.743750  0.052153  1.1584 -49.698  0.111270  0.044782   \n",
       "4500  0.022155  0.548750  0.540930  2.8668  14.402  0.000000  0.022155   \n",
       "\n",
       "           X8       X9      X10   ...        X55       X56       X57      X58  \\\n",
       "Id                                ...                                           \n",
       "3119  0.48075  1.00740  0.32308   ...    19985.0  0.007312  0.003629  0.99269   \n",
       "3687  2.98710  1.54600  0.74919   ...     2443.9  0.124670  0.186370  0.88279   \n",
       "5358  9.21840  1.44620  0.90214   ...    19041.0  0.123660  0.163620  0.87543   \n",
       "3134  0.33163  1.05450  0.24665   ...     4087.9  0.051681  0.132240  0.94832   \n",
       "4500  0.82231  0.61232  0.45125   ...     4408.8  0.066985  0.049097  0.96466   \n",
       "\n",
       "           X59      X60      X61      X62      X63     X64  \n",
       "Id                                                          \n",
       "3119  0.037272  12.3020   4.0442  140.440   2.5991  8.6745  \n",
       "3687  0.044616  11.2790   5.1096   48.732   7.4899  2.8891  \n",
       "5358  0.000000   5.5314   6.8732   21.578  16.9160  3.2526  \n",
       "3134  1.680600   6.5521  33.0650   59.524   6.1319  3.2633  \n",
       "4500  0.558330   1.1969   2.5829  172.720   2.1132  3.6164  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.set_index('Id', inplace=True)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3854, 64), (3854,))"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe C.2: Handling non-numeric features/targets\n",
    "\n",
    "No categorical feature here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe C.3: Transformations\n",
    "No transformation needed here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe C.4: Scaling\n",
    "\n",
    "- Since the 64 features are based on different ranges, I decide to normalize them. \n",
    "- First, de-mean the number, then divide by standard deviation. \n",
    "\n",
    "(The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. For machine learning, every dataset does not require normalization. It is required only when features have different ranges.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    for i in list(df.columns):\n",
    "        df[i] = (df[i] - df[i].mean()) / stdev(df[i])\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>0.004299</td>\n",
       "      <td>-0.033489</td>\n",
       "      <td>-0.141656</td>\n",
       "      <td>-0.036322</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>-0.006723</td>\n",
       "      <td>-0.040002</td>\n",
       "      <td>-0.396774</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049168</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>-0.046525</td>\n",
       "      <td>0.063131</td>\n",
       "      <td>-0.025908</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>-0.032864</td>\n",
       "      <td>-0.049034</td>\n",
       "      <td>-0.075846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>-0.056227</td>\n",
       "      <td>0.054759</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>-0.021422</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.015011</td>\n",
       "      <td>-0.073083</td>\n",
       "      <td>-0.042968</td>\n",
       "      <td>-0.431112</td>\n",
       "      <td>-0.055997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398598</td>\n",
       "      <td>-0.010804</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>-0.010843</td>\n",
       "      <td>0.148670</td>\n",
       "      <td>-0.089122</td>\n",
       "      <td>-0.139682</td>\n",
       "      <td>-0.058218</td>\n",
       "      <td>-0.011295</td>\n",
       "      <td>-0.073296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>-0.047072</td>\n",
       "      <td>0.159681</td>\n",
       "      <td>0.109260</td>\n",
       "      <td>-0.026175</td>\n",
       "      <td>-0.003674</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>-0.087761</td>\n",
       "      <td>-0.045084</td>\n",
       "      <td>-0.365059</td>\n",
       "      <td>-0.135738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.099029</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.145544</td>\n",
       "      <td>-0.076038</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>-0.037908</td>\n",
       "      <td>-0.045531</td>\n",
       "      <td>-0.069274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>0.532882</td>\n",
       "      <td>-0.218142</td>\n",
       "      <td>0.353093</td>\n",
       "      <td>-0.008923</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.649042</td>\n",
       "      <td>-0.024594</td>\n",
       "      <td>0.371771</td>\n",
       "      <td>0.219124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091619</td>\n",
       "      <td>0.186937</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>-0.168885</td>\n",
       "      <td>-0.050881</td>\n",
       "      <td>-0.062126</td>\n",
       "      <td>-0.161076</td>\n",
       "      <td>-0.060435</td>\n",
       "      <td>-0.002138</td>\n",
       "      <td>-0.029828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>-0.139482</td>\n",
       "      <td>-0.036355</td>\n",
       "      <td>-0.001207</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>-0.025768</td>\n",
       "      <td>-0.042135</td>\n",
       "      <td>2.511537</td>\n",
       "      <td>-0.021630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127496</td>\n",
       "      <td>-0.053972</td>\n",
       "      <td>0.013681</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>-0.015656</td>\n",
       "      <td>-0.015730</td>\n",
       "      <td>0.133959</td>\n",
       "      <td>-0.060981</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>-0.054188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "Id                                                                           \n",
       "5691  0.004299 -0.033489 -0.141656 -0.036322 -0.001277  0.048424 -0.006723   \n",
       "1101 -0.056227  0.054759  0.013788 -0.021422  0.000737  0.015011 -0.073083   \n",
       "4461 -0.047072  0.159681  0.109260 -0.026175 -0.003674  0.003628 -0.087761   \n",
       "3715  0.532882 -0.218142  0.353093 -0.008923  0.001773  0.002917  0.649042   \n",
       "4257 -0.021053  0.038190 -0.139482 -0.036355 -0.001207  0.002917 -0.025768   \n",
       "\n",
       "            X8        X9       X10    ...          X55       X56       X57  \\\n",
       "Id                                    ...                                    \n",
       "5691 -0.040002 -0.396774  0.024960    ...    -0.049168  0.033493  0.016356   \n",
       "1101 -0.042968 -0.431112 -0.055997    ...     0.398598 -0.010804  0.007920   \n",
       "4461 -0.045084 -0.365059 -0.135738    ...     0.004565  0.099029  0.011718   \n",
       "3715 -0.024594  0.371771  0.219124    ...    -0.091619  0.186937  0.064336   \n",
       "4257 -0.042135  2.511537 -0.021630    ...    -0.127496 -0.053972  0.013681   \n",
       "\n",
       "           X58       X59       X60       X61       X62       X63       X64  \n",
       "Id                                                                          \n",
       "5691 -0.046525  0.063131 -0.025908  0.012798 -0.032864 -0.049034 -0.075846  \n",
       "1101 -0.010843  0.148670 -0.089122 -0.139682 -0.058218 -0.011295 -0.073296  \n",
       "4461  0.029763  0.145544 -0.076038  0.056063 -0.037908 -0.045531 -0.069274  \n",
       "3715 -0.168885 -0.050881 -0.062126 -0.161076 -0.060435 -0.002138 -0.029828  \n",
       "4257  0.024480 -0.015656 -0.015730  0.133959 -0.060981  0.000529 -0.054188  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(X_train)\n",
    "normalize(X_test)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>0.029838</td>\n",
       "      <td>0.140369</td>\n",
       "      <td>-0.029327</td>\n",
       "      <td>-0.133150</td>\n",
       "      <td>-0.103046</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>0.028969</td>\n",
       "      <td>-0.145844</td>\n",
       "      <td>-0.340674</td>\n",
       "      <td>-0.046649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225929</td>\n",
       "      <td>-0.187915</td>\n",
       "      <td>-0.081874</td>\n",
       "      <td>0.197965</td>\n",
       "      <td>-0.005069</td>\n",
       "      <td>-0.032671</td>\n",
       "      <td>-0.163772</td>\n",
       "      <td>0.080674</td>\n",
       "      <td>-0.251946</td>\n",
       "      <td>-0.057077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>0.039101</td>\n",
       "      <td>-0.288119</td>\n",
       "      <td>0.094274</td>\n",
       "      <td>-0.092711</td>\n",
       "      <td>0.049758</td>\n",
       "      <td>0.019292</td>\n",
       "      <td>0.041086</td>\n",
       "      <td>-0.070491</td>\n",
       "      <td>-0.032786</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112828</td>\n",
       "      <td>0.197705</td>\n",
       "      <td>-0.023961</td>\n",
       "      <td>-0.168461</td>\n",
       "      <td>-0.003887</td>\n",
       "      <td>-0.032678</td>\n",
       "      <td>-0.139674</td>\n",
       "      <td>-0.203902</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>-0.062641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>0.039634</td>\n",
       "      <td>-0.443706</td>\n",
       "      <td>0.319109</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>0.103003</td>\n",
       "      <td>0.019510</td>\n",
       "      <td>0.041031</td>\n",
       "      <td>0.116853</td>\n",
       "      <td>-0.089837</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207698</td>\n",
       "      <td>0.194387</td>\n",
       "      <td>-0.031171</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.011066</td>\n",
       "      <td>-0.032715</td>\n",
       "      <td>-0.099784</td>\n",
       "      <td>-0.288162</td>\n",
       "      <td>0.373373</td>\n",
       "      <td>-0.062292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>0.031942</td>\n",
       "      <td>0.213327</td>\n",
       "      <td>-0.125175</td>\n",
       "      <td>-0.135381</td>\n",
       "      <td>-0.103592</td>\n",
       "      <td>0.026093</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>-0.150327</td>\n",
       "      <td>-0.313750</td>\n",
       "      <td>-0.055498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081078</td>\n",
       "      <td>-0.042125</td>\n",
       "      <td>-0.041116</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>0.259347</td>\n",
       "      <td>-0.032708</td>\n",
       "      <td>0.492637</td>\n",
       "      <td>-0.170414</td>\n",
       "      <td>-0.097644</td>\n",
       "      <td>-0.062282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.394688</td>\n",
       "      <td>-0.068741</td>\n",
       "      <td>0.017149</td>\n",
       "      <td>0.019292</td>\n",
       "      <td>0.030366</td>\n",
       "      <td>-0.135575</td>\n",
       "      <td>-0.566520</td>\n",
       "      <td>-0.031810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074881</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>-0.067465</td>\n",
       "      <td>0.104508</td>\n",
       "      <td>0.078771</td>\n",
       "      <td>-0.032743</td>\n",
       "      <td>-0.196825</td>\n",
       "      <td>0.180840</td>\n",
       "      <td>-0.273168</td>\n",
       "      <td>-0.061942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "Id                                                                           \n",
       "3119  0.029838  0.140369 -0.029327 -0.133150 -0.103046  0.020320  0.028969   \n",
       "3687  0.039101 -0.288119  0.094274 -0.092711  0.049758  0.019292  0.041086   \n",
       "5358  0.039634 -0.443706  0.319109  0.072812  0.103003  0.019510  0.041031   \n",
       "3134  0.031942  0.213327 -0.125175 -0.135381 -0.103592  0.026093  0.031880   \n",
       "4500  0.031242  0.014962  0.394688 -0.068741  0.017149  0.019292  0.030366   \n",
       "\n",
       "            X8        X9       X10    ...          X55       X56       X57  \\\n",
       "Id                                    ...                                    \n",
       "3119 -0.145844 -0.340674 -0.046649    ...     0.225929 -0.187915 -0.081874   \n",
       "3687 -0.070491 -0.032786  0.002684    ...    -0.112828  0.197705 -0.023961   \n",
       "5358  0.116853 -0.089837  0.020392    ...     0.207698  0.194387 -0.031171   \n",
       "3134 -0.150327 -0.313750 -0.055498    ...    -0.081078 -0.042125 -0.041116   \n",
       "4500 -0.135575 -0.566520 -0.031810    ...    -0.074881  0.008161 -0.067465   \n",
       "\n",
       "           X58       X59       X60       X61       X62       X63       X64  \n",
       "Id                                                                          \n",
       "3119  0.197965 -0.005069 -0.032671 -0.163772  0.080674 -0.251946 -0.057077  \n",
       "3687 -0.168461 -0.003887 -0.032678 -0.139674 -0.203902 -0.038330 -0.062641  \n",
       "5358 -0.193001 -0.011066 -0.032715 -0.099784 -0.288162  0.373373 -0.062292  \n",
       "3134  0.050028  0.259347 -0.032708  0.492637 -0.170414 -0.097644 -0.062282  \n",
       "4500  0.104508  0.078771 -0.032743 -0.196825  0.180840 -0.273168 -0.061942  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe Step D: Train a model\n",
    "\n",
    "# Recipe D.1: Select a model\n",
    "\n",
    "I will use the following models one by one and discuss the pros/cons for each of them. Then choose the best-performed one as MyModel.\n",
    "- (1) Naive Bayes\n",
    "- (2) Logistic Regression\n",
    "- (3) K Nearest Neighbors\n",
    "- (4) Decision Tree\n",
    "- (5) Random Forest\n",
    "- (6) Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.2: Fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NB = GaussianNB()\n",
    "model_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.3: Validation and Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Avg cross val score = 0.18\n",
      "Naive Bayes: Accuracy = 92.32%\n"
     ]
    }
   ],
   "source": [
    "model = \"Naive Bayes\"\n",
    "cross_val_avg = np.mean(cross_val_score(model_NB, X_train, y_train, cv=5))\n",
    "\n",
    "print(\"{m:s}: Avg cross val score = {sc:3.2f}\".format(m=model, sc=cross_val_avg) )\n",
    "\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = model_NB.predict (X_test))\n",
    "print(\"{m:s}: Accuracy = {a:.2%}\".format(m=model, a=accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Naive Bayes on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17488323819408408"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train = model_NB.score(X_train,y_train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.4: Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that average cross val score & accuracy on the training set are extremely low. \n",
    "- Naive Bayes is certainly not a good model to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Logistic Regression with no additional feature engineering\n",
    "- Since there are already 64 features, I decided not to create new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.2: Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LogisticReg = LogisticRegression()\n",
    "model_LogisticReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.3: Validation and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, version 0: Avg cross val score = 0.94\n",
      "Logistic Regression, version 0: Accuracy = 92.01%\n"
     ]
    }
   ],
   "source": [
    "model = \"Logistic Regression, version 0\"\n",
    "cross_val_avg = np.mean(cross_val_score(model_LogisticReg, X_train, y_train, cv=5))\n",
    "\n",
    "print(\"{m:s}: Avg cross val score = {sc:3.2f}\".format(m=model, sc=cross_val_avg) )\n",
    "\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = model_LogisticReg.predict (X_test))\n",
    "print(\"{m:s}: Accuracy = {a:.2%}\".format(m=model, a=accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Logistic Regression on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9423975090814738"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train = model_LogisticReg.score(X_train,y_train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.4: Error Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9201244813278008\n",
      "Recall: 0.935965848452508\n",
      "Specificity: 0.37037037037037035\n",
      "Precision: 0.9809843400447428\n",
      "False positive rate: 0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_true = y_test, y_pred = model_LogisticReg.predict (X_test))\n",
    "matrix\n",
    "\n",
    "TP, FP, FN, TN = matrix.ravel()\n",
    "TP, FP, FN, TN\n",
    "\n",
    "accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "recall = TP/(TP + FN)\n",
    "specificity = TN / (TN+FP)\n",
    "precision = TP / (TP+FP)\n",
    "false_positive_rate = FP/ (FP+TN)\n",
    "#f1_score = f1_score(y_true = y_test, y_pred = model_LogisticReg.predict (X_test))\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\",specificity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"False positive rate:\", false_positive_rate)\n",
    "#print(\"F1 score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy of logistic regression on both test and training sets is high, which is good.\n",
    "- Recall & precision are also high, which is good.\n",
    "- However, **specificity is very low & false positive is very high.**\n",
    "\n",
    "> The low specificity and high false positive rates might be caused by imbalanced classes (i.e. \"Bankrupt\" column has a lot of zeros, but only a few ones). To increase specificity and lower false positive rate, I will do **resampling** in the extra credit part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.2: Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_KNN = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "model_KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.3: Validation and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Avg cross val score = 0.94\n",
      "KNN: Accuracy = 92.43%\n"
     ]
    }
   ],
   "source": [
    "model = \"KNN\"\n",
    "cross_val_avg = np.mean(cross_val_score(model_KNN, X_train, y_train, cv=5))\n",
    "\n",
    "print(\"{m:s}: Avg cross val score = {sc:3.2f}\".format(m=model, sc=cross_val_avg) )\n",
    "\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = model_KNN.predict (X_test))\n",
    "print(\"{m:s}: Accuracy = {a:.2%}\".format(m=model, a=accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of KNN on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9481058640373637"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train = model_KNN.score(X_train,y_train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.4: Error Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9242738589211619\n",
      "Recall: 0.928944618599791\n",
      "Specificity: 0.2857142857142857\n",
      "Precision: 0.9944071588366891\n",
      "False positive rate: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_true = y_test, y_pred = model_KNN.predict (X_test))\n",
    "matrix\n",
    "\n",
    "TP, FP, FN, TN = matrix.ravel()\n",
    "TP, FP, FN, TN\n",
    "\n",
    "accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "recall = TP/(TP + FN)\n",
    "specificity = TN / (TN+FP)\n",
    "precision = TP / (TP+FP)\n",
    "false_positive_rate = FP/ (FP+TN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\",specificity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"False positive rate:\", false_positive_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as Logistic Regression,\n",
    "- The accuracy of logistic regression on both test and training sets is high, which is good.\n",
    "- Recall & precision are also high, which is good.\n",
    "- However, **specificity** is very low & **false positive** is very high. \n",
    "\n",
    "> The low specificity and high false positive rates might be caused by imbalanced classes (i.e. \"Bankrupt\" column has a lot of zeros, but only a few ones). To increase specificity and lower false positive rate, I will do **resampling** in the extra credit part.\n",
    "\n",
    "- **In addition, I found the execution time for the KNN model is longer than NB and Logistic. One of the cons of KNN model is the high memory requirement. All of the training data must be present in memory in order to calculate the closest K neighbors. **\n",
    "- **As we have thousands of lines of data here, KNN is not an optimal choice for us. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Decision Tree (DT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.2: Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DT = DecisionTreeClassifier()\n",
    "model_DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.3: Validation and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Avg cross val score = 0.92\n",
      "Decision Tree: Accuracy = 33.40%\n"
     ]
    }
   ],
   "source": [
    "model = \"Decision Tree\"\n",
    "cross_val_avg = np.mean(cross_val_score(model_DT, X_train, y_train, cv=5))\n",
    "\n",
    "print(\"{m:s}: Avg cross val score = {sc:3.2f}\".format(m=model, sc=cross_val_avg) )\n",
    "\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = model_DT.predict (X_test))\n",
    "print(\"{m:s}: Accuracy = {a:.2%}\".format(m=model, a=accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Decision Tree on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train = model_DT.score(X_train,y_train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.4: Error Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.33402489626556015\n",
      "Recall: 0.9436619718309859\n",
      "Specificity: 0.07941176470588235\n",
      "Precision: 0.29977628635346754\n",
      "False positive rate: 0.9205882352941176\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_true = y_test, y_pred = model_DT.predict (X_test))\n",
    "matrix\n",
    "\n",
    "TP, FP, FN, TN = matrix.ravel()\n",
    "TP, FP, FN, TN\n",
    "\n",
    "accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "recall = TP/(TP + FN)\n",
    "specificity = TN / (TN+FP)\n",
    "precision = TP / (TP+FP)\n",
    "false_positive_rate = FP/ (FP+TN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\",specificity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"False positive rate:\", false_positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is certainly not a good model to use.\n",
    "- very low accuracy, specificity & precision \n",
    "- very high false positive rate \n",
    "- long execution time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.2: Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.3: Validation and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Avg cross val score = 0.95\n",
      "Random Forest: Accuracy = 39.52%\n"
     ]
    }
   ],
   "source": [
    "model = \"Random Forest\"\n",
    "cross_val_avg = np.mean(cross_val_score(model_RF, X_train, y_train, cv=5))\n",
    "\n",
    "print(\"{m:s}: Avg cross val score = {sc:3.2f}\".format(m=model, sc=cross_val_avg) )\n",
    "\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = model_RF.predict (X_test))\n",
    "print(\"{m:s}: Accuracy = {a:.2%}\".format(m=model, a=accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Random Forest on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train = model_RF.score(X_train,y_train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.4: Error Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39522821576763484\n",
      "Recall: 0.9507246376811594\n",
      "Specificity: 0.08562197092084006\n",
      "Precision: 0.3668903803131991\n",
      "False positive rate: 0.9143780290791599\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_true = y_test, y_pred = model_RF.predict (X_test))\n",
    "matrix\n",
    "\n",
    "TP, FP, FN, TN = matrix.ravel()\n",
    "TP, FP, FN, TN\n",
    "\n",
    "accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "recall = TP/(TP + FN)\n",
    "specificity = TN / (TN+FP)\n",
    "precision = TP / (TP+FP)\n",
    "false_positive_rate = FP/ (FP+TN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\",specificity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"False positive rate:\", false_positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is certainly not a good model to use.\n",
    "- very low accuracy, specificity & precision \n",
    "- very high false positive rate \n",
    "- long execution time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.2: Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SVM = SVC(gamma=\"auto\")\n",
    "model_SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.3: Validation and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Avg cross val score = 0.94\n",
      "SVM: Accuracy = 92.74%\n"
     ]
    }
   ],
   "source": [
    "model = \"SVM\"\n",
    "cross_val_avg = np.mean(cross_val_score(model_SVM, X_train, y_train, cv=5))\n",
    "\n",
    "print(\"{m:s}: Avg cross val score = {sc:3.2f}\".format(m=model, sc=cross_val_avg) )\n",
    "\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = model_SVM.predict (X_test))\n",
    "print(\"{m:s}: Accuracy = {a:.2%}\".format(m=model, a=accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of SVM on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9436948624805397"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train = model_SVM.score(X_train,y_train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe D.4: Error Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(894, 0, 70, 0)"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_true = y_test, y_pred = model_SVM.predict (X_test))\n",
    "matrix\n",
    "\n",
    "TP, FP, FN, TN = matrix.ravel()\n",
    "TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9273858921161826\n",
      "Recall: 0.9273858921161826\n",
      "Specificity: nan\n",
      "Precision: 1.0\n",
      "False positive rate: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WendiZhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/WendiZhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "recall = TP/(TP + FN)\n",
    "specificity = TN / (TN+FP)\n",
    "precision = TP / (TP+FP)\n",
    "false_positive_rate = FP/ (FP+TN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\",specificity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"False positive rate:\", false_positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is certainly not a good model to use.\n",
    "- SVM fails to correctly predict negative cases (TN=0, FN=70)\n",
    "- relatively long execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a conclusion, Logistic Regression is the optimal model to use as Mymodel.\n",
    "### However, we need to deal with the issue of imbalanced classes, in order to improve its performance on specificity and false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra credit opportunities\n",
    "- Address the issue of: classes being imbalanced\n",
    "- Address the issue of: Different importance of each type of misclassification\n",
    "    - It is 5 times worse to misclassify a company that *does go bankrupt* than to misclassify a company that does not go bankrupt\n",
    "        - Suppose we invest in a company for which we predict it will not go bankrupt\n",
    "            - We incur substantial losses for a bad investment\n",
    "        - The loss from not investing in a company that we incorrectly classify as going bankrupt is small (opportunity cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Address the issue of: classes being imbalanced\n",
    "- I decided to **oversample** (rather than undersample) the training data by adding more copies of the minority class (where \"Bankrupt\" = 1), since we  do not have a ton of data to work with (less than 4k rows).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>0.004299</td>\n",
       "      <td>-0.033489</td>\n",
       "      <td>-0.141656</td>\n",
       "      <td>-0.036322</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>-0.006723</td>\n",
       "      <td>-0.040002</td>\n",
       "      <td>-0.396774</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049168</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>-0.046525</td>\n",
       "      <td>0.063131</td>\n",
       "      <td>-0.025908</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>-0.032864</td>\n",
       "      <td>-0.049034</td>\n",
       "      <td>-0.075846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>-0.056227</td>\n",
       "      <td>0.054759</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>-0.021422</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.015011</td>\n",
       "      <td>-0.073083</td>\n",
       "      <td>-0.042968</td>\n",
       "      <td>-0.431112</td>\n",
       "      <td>-0.055997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398598</td>\n",
       "      <td>-0.010804</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>-0.010843</td>\n",
       "      <td>0.148670</td>\n",
       "      <td>-0.089122</td>\n",
       "      <td>-0.139682</td>\n",
       "      <td>-0.058218</td>\n",
       "      <td>-0.011295</td>\n",
       "      <td>-0.073296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>-0.047072</td>\n",
       "      <td>0.159681</td>\n",
       "      <td>0.109260</td>\n",
       "      <td>-0.026175</td>\n",
       "      <td>-0.003674</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>-0.087761</td>\n",
       "      <td>-0.045084</td>\n",
       "      <td>-0.365059</td>\n",
       "      <td>-0.135738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.099029</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.145544</td>\n",
       "      <td>-0.076038</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>-0.037908</td>\n",
       "      <td>-0.045531</td>\n",
       "      <td>-0.069274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>0.532882</td>\n",
       "      <td>-0.218142</td>\n",
       "      <td>0.353093</td>\n",
       "      <td>-0.008923</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.649042</td>\n",
       "      <td>-0.024594</td>\n",
       "      <td>0.371771</td>\n",
       "      <td>0.219124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091619</td>\n",
       "      <td>0.186937</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>-0.168885</td>\n",
       "      <td>-0.050881</td>\n",
       "      <td>-0.062126</td>\n",
       "      <td>-0.161076</td>\n",
       "      <td>-0.060435</td>\n",
       "      <td>-0.002138</td>\n",
       "      <td>-0.029828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>-0.139482</td>\n",
       "      <td>-0.036355</td>\n",
       "      <td>-0.001207</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>-0.025768</td>\n",
       "      <td>-0.042135</td>\n",
       "      <td>2.511537</td>\n",
       "      <td>-0.021630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127496</td>\n",
       "      <td>-0.053972</td>\n",
       "      <td>0.013681</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>-0.015656</td>\n",
       "      <td>-0.015730</td>\n",
       "      <td>0.133959</td>\n",
       "      <td>-0.060981</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>-0.054188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "Id                                                                           \n",
       "5691  0.004299 -0.033489 -0.141656 -0.036322 -0.001277  0.048424 -0.006723   \n",
       "1101 -0.056227  0.054759  0.013788 -0.021422  0.000737  0.015011 -0.073083   \n",
       "4461 -0.047072  0.159681  0.109260 -0.026175 -0.003674  0.003628 -0.087761   \n",
       "3715  0.532882 -0.218142  0.353093 -0.008923  0.001773  0.002917  0.649042   \n",
       "4257 -0.021053  0.038190 -0.139482 -0.036355 -0.001207  0.002917 -0.025768   \n",
       "\n",
       "            X8        X9       X10    ...          X55       X56       X57  \\\n",
       "Id                                    ...                                    \n",
       "5691 -0.040002 -0.396774  0.024960    ...    -0.049168  0.033493  0.016356   \n",
       "1101 -0.042968 -0.431112 -0.055997    ...     0.398598 -0.010804  0.007920   \n",
       "4461 -0.045084 -0.365059 -0.135738    ...     0.004565  0.099029  0.011718   \n",
       "3715 -0.024594  0.371771  0.219124    ...    -0.091619  0.186937  0.064336   \n",
       "4257 -0.042135  2.511537 -0.021630    ...    -0.127496 -0.053972  0.013681   \n",
       "\n",
       "           X58       X59       X60       X61       X62       X63       X64  \n",
       "Id                                                                          \n",
       "5691 -0.046525  0.063131 -0.025908  0.012798 -0.032864 -0.049034 -0.075846  \n",
       "1101 -0.010843  0.148670 -0.089122 -0.139682 -0.058218 -0.011295 -0.073296  \n",
       "4461  0.029763  0.145544 -0.076038  0.056063 -0.037908 -0.045531 -0.069274  \n",
       "3715 -0.168885 -0.050881 -0.062126 -0.161076 -0.060435 -0.002138 -0.029828  \n",
       "4257  0.024480 -0.015656 -0.015730  0.133959 -0.060981  0.000529 -0.054188  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bankrupt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bankrupt\n",
       "Id            \n",
       "5691         0\n",
       "1101         0\n",
       "4461         0\n",
       "3715         0\n",
       "4257         0"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df = pd.DataFrame(data = y_train)\n",
    "y_train_df['Id'] = list(X_train.index)\n",
    "\n",
    "y_train_df.set_index('Id', inplace=True)\n",
    "\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>0.004299</td>\n",
       "      <td>-0.033489</td>\n",
       "      <td>-0.141656</td>\n",
       "      <td>-0.036322</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>-0.006723</td>\n",
       "      <td>-0.040002</td>\n",
       "      <td>-0.396774</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>-0.046525</td>\n",
       "      <td>0.063131</td>\n",
       "      <td>-0.025908</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>-0.032864</td>\n",
       "      <td>-0.049034</td>\n",
       "      <td>-0.075846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>-0.056227</td>\n",
       "      <td>0.054759</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>-0.021422</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.015011</td>\n",
       "      <td>-0.073083</td>\n",
       "      <td>-0.042968</td>\n",
       "      <td>-0.431112</td>\n",
       "      <td>-0.055997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010804</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>-0.010843</td>\n",
       "      <td>0.148670</td>\n",
       "      <td>-0.089122</td>\n",
       "      <td>-0.139682</td>\n",
       "      <td>-0.058218</td>\n",
       "      <td>-0.011295</td>\n",
       "      <td>-0.073296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>-0.047072</td>\n",
       "      <td>0.159681</td>\n",
       "      <td>0.109260</td>\n",
       "      <td>-0.026175</td>\n",
       "      <td>-0.003674</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>-0.087761</td>\n",
       "      <td>-0.045084</td>\n",
       "      <td>-0.365059</td>\n",
       "      <td>-0.135738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099029</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.145544</td>\n",
       "      <td>-0.076038</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>-0.037908</td>\n",
       "      <td>-0.045531</td>\n",
       "      <td>-0.069274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>0.532882</td>\n",
       "      <td>-0.218142</td>\n",
       "      <td>0.353093</td>\n",
       "      <td>-0.008923</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.649042</td>\n",
       "      <td>-0.024594</td>\n",
       "      <td>0.371771</td>\n",
       "      <td>0.219124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186937</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>-0.168885</td>\n",
       "      <td>-0.050881</td>\n",
       "      <td>-0.062126</td>\n",
       "      <td>-0.161076</td>\n",
       "      <td>-0.060435</td>\n",
       "      <td>-0.002138</td>\n",
       "      <td>-0.029828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>-0.139482</td>\n",
       "      <td>-0.036355</td>\n",
       "      <td>-0.001207</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>-0.025768</td>\n",
       "      <td>-0.042135</td>\n",
       "      <td>2.511537</td>\n",
       "      <td>-0.021630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053972</td>\n",
       "      <td>0.013681</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>-0.015656</td>\n",
       "      <td>-0.015730</td>\n",
       "      <td>0.133959</td>\n",
       "      <td>-0.060981</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>-0.054188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "Id                                                                           \n",
       "5691  0.004299 -0.033489 -0.141656 -0.036322 -0.001277  0.048424 -0.006723   \n",
       "1101 -0.056227  0.054759  0.013788 -0.021422  0.000737  0.015011 -0.073083   \n",
       "4461 -0.047072  0.159681  0.109260 -0.026175 -0.003674  0.003628 -0.087761   \n",
       "3715  0.532882 -0.218142  0.353093 -0.008923  0.001773  0.002917  0.649042   \n",
       "4257 -0.021053  0.038190 -0.139482 -0.036355 -0.001207  0.002917 -0.025768   \n",
       "\n",
       "            X8        X9       X10    ...          X56       X57       X58  \\\n",
       "Id                                    ...                                    \n",
       "5691 -0.040002 -0.396774  0.024960    ...     0.033493  0.016356 -0.046525   \n",
       "1101 -0.042968 -0.431112 -0.055997    ...    -0.010804  0.007920 -0.010843   \n",
       "4461 -0.045084 -0.365059 -0.135738    ...     0.099029  0.011718  0.029763   \n",
       "3715 -0.024594  0.371771  0.219124    ...     0.186937  0.064336 -0.168885   \n",
       "4257 -0.042135  2.511537 -0.021630    ...    -0.053972  0.013681  0.024480   \n",
       "\n",
       "           X59       X60       X61       X62       X63       X64  Bankrupt  \n",
       "Id                                                                          \n",
       "5691  0.063131 -0.025908  0.012798 -0.032864 -0.049034 -0.075846         0  \n",
       "1101  0.148670 -0.089122 -0.139682 -0.058218 -0.011295 -0.073296         0  \n",
       "4461  0.145544 -0.076038  0.056063 -0.037908 -0.045531 -0.069274         0  \n",
       "3715 -0.050881 -0.062126 -0.161076 -0.060435 -0.002138 -0.029828         0  \n",
       "4257 -0.015656 -0.015730  0.133959 -0.060981  0.000529 -0.054188         0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train_df], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>-0.122196</td>\n",
       "      <td>0.180237</td>\n",
       "      <td>-0.068379</td>\n",
       "      <td>-0.011356</td>\n",
       "      <td>0.086883</td>\n",
       "      <td>-0.048090</td>\n",
       "      <td>-0.142713</td>\n",
       "      <td>-0.045467</td>\n",
       "      <td>-1.279793</td>\n",
       "      <td>-0.155158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.666302</td>\n",
       "      <td>-0.010229</td>\n",
       "      <td>0.344936</td>\n",
       "      <td>0.419476</td>\n",
       "      <td>-0.103875</td>\n",
       "      <td>-0.234128</td>\n",
       "      <td>0.372037</td>\n",
       "      <td>-0.072928</td>\n",
       "      <td>-0.077210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>-0.063917</td>\n",
       "      <td>-0.060341</td>\n",
       "      <td>-0.149858</td>\n",
       "      <td>-0.036701</td>\n",
       "      <td>-0.004753</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>-0.085808</td>\n",
       "      <td>-0.045144</td>\n",
       "      <td>-0.432423</td>\n",
       "      <td>-0.213574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012487</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>-0.009486</td>\n",
       "      <td>0.078949</td>\n",
       "      <td>-0.102134</td>\n",
       "      <td>-0.103292</td>\n",
       "      <td>-0.008514</td>\n",
       "      <td>-0.058576</td>\n",
       "      <td>-0.074710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>-0.966929</td>\n",
       "      <td>0.760617</td>\n",
       "      <td>-0.647671</td>\n",
       "      <td>-0.040774</td>\n",
       "      <td>-0.007179</td>\n",
       "      <td>-0.419958</td>\n",
       "      <td>-0.979957</td>\n",
       "      <td>-0.050788</td>\n",
       "      <td>0.401930</td>\n",
       "      <td>-0.700110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320351</td>\n",
       "      <td>0.139012</td>\n",
       "      <td>0.229681</td>\n",
       "      <td>-0.050881</td>\n",
       "      <td>-0.100852</td>\n",
       "      <td>-0.058360</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>-0.063923</td>\n",
       "      <td>-0.057399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>0.051308</td>\n",
       "      <td>0.166695</td>\n",
       "      <td>0.242876</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.000365</td>\n",
       "      <td>-0.036026</td>\n",
       "      <td>0.058182</td>\n",
       "      <td>-0.045217</td>\n",
       "      <td>5.139654</td>\n",
       "      <td>-0.142311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055764</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.275710</td>\n",
       "      <td>-0.039181</td>\n",
       "      <td>0.341926</td>\n",
       "      <td>-0.072239</td>\n",
       "      <td>0.229287</td>\n",
       "      <td>-0.004283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>-0.388642</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>-0.399651</td>\n",
       "      <td>-0.041809</td>\n",
       "      <td>-0.005664</td>\n",
       "      <td>-0.059132</td>\n",
       "      <td>-0.406797</td>\n",
       "      <td>-0.046024</td>\n",
       "      <td>-0.549360</td>\n",
       "      <td>-0.203158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194422</td>\n",
       "      <td>-0.125199</td>\n",
       "      <td>0.137011</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>-0.089948</td>\n",
       "      <td>0.122301</td>\n",
       "      <td>-0.012909</td>\n",
       "      <td>-0.057399</td>\n",
       "      <td>-0.072848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "Id                                                                           \n",
       "2616 -0.122196  0.180237 -0.068379 -0.011356  0.086883 -0.048090 -0.142713   \n",
       "4788 -0.063917 -0.060341 -0.149858 -0.036701 -0.004753  0.004693 -0.085808   \n",
       "3534 -0.966929  0.760617 -0.647671 -0.040774 -0.007179 -0.419958 -0.979957   \n",
       "3793  0.051308  0.166695  0.242876 -0.013459 -0.000365 -0.036026  0.058182   \n",
       "4626 -0.388642  0.139500 -0.399651 -0.041809 -0.005664 -0.059132 -0.406797   \n",
       "\n",
       "            X8        X9       X10    ...          X56       X57       X58  \\\n",
       "Id                                    ...                                    \n",
       "2616 -0.045467 -1.279793 -0.155158    ...    -0.666302 -0.010229  0.344936   \n",
       "4788 -0.045144 -0.432423 -0.213574    ...    -0.012487  0.008686 -0.009486   \n",
       "3534 -0.050788  0.401930 -0.700110    ...    -0.320351  0.139012  0.229681   \n",
       "3793 -0.045217  5.139654 -0.142311    ...    -0.055764  0.039721  0.021872   \n",
       "4626 -0.046024 -0.549360 -0.203158    ...    -0.194422 -0.125199  0.137011   \n",
       "\n",
       "           X59       X60       X61       X62       X63       X64  Bankrupt  \n",
       "Id                                                                          \n",
       "2616  0.419476 -0.103875 -0.234128  0.372037 -0.072928 -0.077210         1  \n",
       "4788  0.078949 -0.102134 -0.103292 -0.008514 -0.058576 -0.074710         1  \n",
       "3534 -0.050881 -0.100852 -0.058360  0.022721 -0.063923 -0.057399         1  \n",
       "3793  0.275710 -0.039181  0.341926 -0.072239  0.229287 -0.004283         1  \n",
       "4626  0.059998 -0.089948  0.122301 -0.012909 -0.057399 -0.072848         1  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate minority and majority classes\n",
    "not_bankrupt = X[X.Bankrupt == 0]\n",
    "bankrupt = X[X.Bankrupt == 1]\n",
    "\n",
    "bankrupt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample minority\n",
    "bankrupt_oversampled = resample(bankrupt,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_bankrupt), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3854, 65), (7232, 65))"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine majority and oversampled minority\n",
    "X_oversampled = pd.concat([not_bankrupt, bankrupt_oversampled])\n",
    "\n",
    "X.shape, X_oversampled.shape #check if X is indeed oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3616, 3616)"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check new class counts\n",
    "list(X_oversampled['Bankrupt']).count(0), list(X_oversampled['Bankrupt']).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5785, 64), (1447, 64), (5785,), (1447,))"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_test_split again\n",
    "X_train_O, X_test_O, y_train_O, y_test_O = train_test_split(\n",
    "    X_oversampled.drop(columns = ['Bankrupt']), X_oversampled['Bankrupt'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_O.shape, X_test_O.shape, y_train_O.shape, y_test_O.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run logistic regression again with the balanced training data\n",
    "model_LogisticReg = LogisticRegression()\n",
    "model_LogisticReg.fit(X_train_O, y_train_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, oversampled version: Avg cross val score = 0.79\n",
      "Logistic Regression, oversampled version: Accuracy = 81.20%\n"
     ]
    }
   ],
   "source": [
    "model = \"Logistic Regression, oversampled version\"\n",
    "cross_val_avg = np.mean(cross_val_score(model_LogisticReg, X_train_O, y_train_O, cv=5))\n",
    "\n",
    "print(\"{m:s}: Avg cross val score = {sc:3.2f}\".format(m=model, sc=cross_val_avg) )\n",
    "\n",
    "accuracy = accuracy_score(y_true = y_test_O, y_pred = model_LogisticReg.predict (X_test_O))\n",
    "print(\"{m:s}: Accuracy = {a:.2%}\".format(m=model, a=accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Logistic Regression on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8025929127052722"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train = model_LogisticReg.score(X_train_O,y_train_O)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8120248790601244\n",
      "Recall: 0.7906976744186046\n",
      "Specificity: 0.836552748885587\n",
      "Precision: 0.8476454293628809\n",
      "False positive rate: 0.16344725111441308\n",
      "F1 score: 0.8054363376251789\n"
     ]
    }
   ],
   "source": [
    "# Let's also check F1 score here \n",
    "# Note: F1 score is the weighted average of the precision and recall\n",
    "# An F1 score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "matrix = confusion_matrix(y_true = y_test_O, y_pred = model_LogisticReg.predict (X_test_O))\n",
    "matrix\n",
    "\n",
    "TP, FP, FN, TN = matrix.ravel()\n",
    "TP, FP, FN, TN\n",
    "\n",
    "accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "recall = TP/(TP + FN)\n",
    "specificity = TN / (TN+FP)\n",
    "precision = TP / (TP+FP)\n",
    "false_positive_rate = FP/ (FP+TN)\n",
    "f1_score = f1_score(y_test_O, model_LogisticReg.predict (X_test_O))\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\",specificity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"False positive rate:\", false_positive_rate)\n",
    "print(\"F1 score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy: with balanced training data, we sacrifice some accuracy (0.81<0.92)\n",
    "- Recall: with balanced training data, we also sacrifice some recall (0.79<0.94)\n",
    "- Precision: with balanced training data, we also sacrifice some precision (0.85<0.98)\n",
    " \n",
    "**However, the new accuracy, recall and precision rates are still desirable.**\n",
    "\n",
    "**In return, we now obtain a high specificity rate (0.84>0.37), a low false positive rate (0.16<0.63) and a high F1 score (a F1 score reaches its best value at 1 and worst score at 0).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Address the issue of: Different importance of each type of misclassification\n",
    "    - It is **5 times** worse to misclassify a company that *does go bankrupt* than to misclassify a company that \n",
    "    does not go bankrupt \n",
    "    - Suppose we invest in a company for which we predict it will not go bankrupt\n",
    "    - We incur substantial losses for a bad investment\n",
    "    - The loss from not investing in a company that we incorrectly classify as going bankrupt is small (opportunity cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some background notes:\n",
    "- **Cost**: The penalty associated with an incorrect prediction.\n",
    "The goal of cost-sensitive learning is to minimize the cost of a model on the training dataset, where it is assumed that different types of prediction errors have a different and known associated cost.\n",
    "- **Cost Minimization**: The goal of cost-sensitive learning is to minimize the cost of a model on a training dataset.\n",
    "- **Cost Matrix**: A matrix that assigns a cost to each cell in the confusion matrix.\n",
    "- All of the following exercises will be conducted based on the **imbalanced training data X_train & y_train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | Bankrupt | Not Bankrupt  |\n",
    "|-|-----|-----|\n",
    "|**Bankrupt**| TP | FP |\n",
    "|**Not Bankrupt**| FN | TN |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Matrix\n",
    "| | Bankrupt (1) | Not Bankrupt (0)  |\n",
    "|-|-----|-----|\n",
    "|**Bankrupt (1)**| 0 | 10 |\n",
    "|**Not Bankrupt (0)**| 50 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: costcla in /Users/WendiZhang/anaconda3/lib/python3.6/site-packages (0.5)\n",
      "Requirement already satisfied: pandas>=0.14.0 in /Users/WendiZhang/anaconda3/lib/python3.6/site-packages (from costcla) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /Users/WendiZhang/anaconda3/lib/python3.6/site-packages (from costcla) (1.14.3)\n",
      "Requirement already satisfied: pyea>=0.2 in /Users/WendiZhang/anaconda3/lib/python3.6/site-packages (from costcla) (0.2)\n",
      "Requirement already satisfied: scikit-learn>=0.15.0b2 in /Users/WendiZhang/anaconda3/lib/python3.6/site-packages (from costcla) (0.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/WendiZhang/anaconda3/lib/python3.6/site-packages (from pandas>=0.14.0->costcla) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/WendiZhang/anaconda3/lib/python3.6/site-packages (from pandas>=0.14.0->costcla) (2018.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/WendiZhang/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.14.0->costcla) (1.11.0)\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install costcla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from costcla.metrics import cost_loss\n",
    "from costcla.models import CostSensitiveLogisticRegression, CostSensitiveDecisionTreeClassifier, CostSensitiveRandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: create a cost matrix\n",
    "- the columns represent the costs of false positives, false negatives, true positives and true negatives, for each example\n",
    "- Such sequence is aligned with the parameter **\"cost_mat\"** which we will use in the **\"fit\"** command\n",
    "\n",
    "> False Positive (FP): misclassify a company that *does NOT go bankrupt* as *bankrupt*,  cost = 10\n",
    "\n",
    "> False Negative (FN): misclassify a company that *does go bankrupt* as *NOT bankrupt*,  cost = 50\n",
    "\n",
    "> True Positive (TP) & True Negative (TN): correct classification, cost = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_mat_train = np.zeros((len(y_train),4))\n",
    "cost_mat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10., 50.,  0.,  0.],\n",
       "       [10., 50.,  0.,  0.],\n",
       "       [10., 50.,  0.,  0.],\n",
       "       ...,\n",
       "       [10., 50.,  0.,  0.],\n",
       "       [10., 50.,  0.,  0.],\n",
       "       [10., 50.,  0.,  0.]])"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#false positives cost=10\n",
    "cost_mat_train[:,0] = 10\n",
    "\n",
    "#false negatives cost=50\n",
    "cost_mat_train[:,1] = 50\n",
    "\n",
    "cost_mat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3854, 4)"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_mat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(964, 4)"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat the same to the test set\n",
    "cost_mat_test = np.zeros((len(y_test),4))\n",
    "\n",
    "cost_mat_test[:,0]=10\n",
    "cost_mat_test[:,1]=50\n",
    "\n",
    "cost_mat_test\n",
    "cost_mat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: fit Cost Sensitive Logistic Regression (CSLR) model & compare cost loss with the regular Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CSLR = CostSensitiveLogisticRegression()\n",
    "model_CSLR.fit(X_train, y_train, cost_mat_train)\n",
    "\n",
    "model_LogisticReg = LogisticRegression()\n",
    "model_LogisticReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100.0 3170.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_CSLR = model_CSLR.predict(X_test)\n",
    "y_pred_LR = model_LogisticReg.predict(X_test)\n",
    "\n",
    "print (cost_loss(y_test, y_pred_CSLR, cost_mat_test), cost_loss(y_test, y_pred_LR, cost_mat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Surprisingly, cost sensitive learning actually does slightly worse for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: fit Cost Sensitive Decision Tree (CSDT) & compare cost loss with the regular Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CSDT = CostSensitiveDecisionTreeClassifier()\n",
    "model_CSDT.fit(np.array(X_train), np.array(y_train), cost_mat_train)\n",
    "\n",
    "model_DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6340.0 7370.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_CSDT = model_CSDT.predict(np.array(X_test))\n",
    "y_pred_DT = model_DT.predict(np.array(X_test))\n",
    "\n",
    "print (cost_loss(np.array(y_test), y_pred_CSDT, cost_mat_test), cost_loss(np.array(y_test), y_pred_DT, cost_mat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1397557666214383"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - cost_loss(np.array(y_test), y_pred_CSDT, cost_mat_test) / cost_loss(np.array(y_test), y_pred_DT, cost_mat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cost sensitive learning does better than regular learning for decision tree, as cost loss is now lower by 0.19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: fit Cost Sensitive Random Forest (CSRF) & compare cost loss with the regular Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CSRF = CostSensitiveRandomForestClassifier()\n",
    "model_CSRF.fit(np.array(X_train), np.array(y_train), cost_mat_train)\n",
    "\n",
    "model_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3470.0 6510.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_CSRF = model_CSRF.predict(np.array(X_test))\n",
    "y_pred_RF = model_RF.predict(np.array(X_test))\n",
    "\n",
    "print (cost_loss(np.array(y_test), y_pred_CSRF, cost_mat_test), cost_loss(np.array(y_test), y_pred_RF, cost_mat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46697388632872505"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- (cost_loss(np.array(y_test), y_pred_CSRF, cost_mat_test) / cost_loss(np.array(y_test), y_pred_RF, cost_mat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cost sensitive learning does better than regular learning for random forest, as cost loss is now lower by 0.46.\n",
    "- The performance of random forest is better than decision tree (0.46 > 0.19).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a conclusion, WHEN CONSIDERING THE COST OF MISCLASSIFICATION, cost-sensitive random forest is the optimal model.\n",
    "- In general cases, we still want to use logistic regression, since it's easier to implement and more widely used.\n",
    "- **So I use logistic regression as MyModel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission guidelines\n",
    "\n",
    "**In addition** to showing your mastery, there is one task you must perform to make grading easier.\n",
    "\n",
    "- You will implement the body of a subroutine `MyModel`\n",
    "    - that takes as argument, the name of a CSV file containing the test set\n",
    "    - performs predictions on each example in the test set\n",
    "    - returns an array or predictions with a one-to-one correspondence with the examples in the test set\n",
    "    \n",
    "- You will call the subroutine, passing the name of the test set file that we will supply.\n",
    "\n",
    "In this way, we can get the results of your model by executing a single cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MyModel` has one *required* parameter: `fileName`\n",
    "- you may add additional parameters as you need\n",
    "\n",
    "`MyModel` is where you will perform whatever pre-processing you require, for example\n",
    "- imputing missing values\n",
    "- transformations\n",
    "- whatever else you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the cell **that must appear as the last cell in your notebook**\n",
    "- It points to a test file\n",
    "- Your code must make predictions on this test file\n",
    "- There are *no labels* visible to you in the test file; these are available only to the grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"5th_yr.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file:  ./data/midterm_project/bankruptcy/holdout/5th_yr.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_PATH = \"./data/midterm_project/bankruptcy/holdout\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "testFileName = os.path.join(TEST_PATH, data_file)\n",
    "\n",
    "def MyModel(fileName=None):\n",
    "    print(\"Test file: \", fileName)\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    ## Get the data:\n",
    "    test_data = pd.read_csv(fileName)\n",
    "    \n",
    "    ## Cleaning:\n",
    "    #(1) Replace all \"?\" with NaN, then change data type from object to float64\n",
    "    test_data = test_data.replace('?', np.NaN)\n",
    "    \n",
    "    test_data = test_data.astype('float64')\n",
    "    test_data['Id'] = test_data['Id'].astype('int64')\n",
    "    \n",
    "    #(2) Replace NaN with median\n",
    "    test_data_median = test_data.median()\n",
    "    test_data.fillna(test_data_median, inplace = True)\n",
    "\n",
    "    #(3) Set \"Id\" as index\n",
    "    test_data.set_index('Id', inplace=True)\n",
    "\n",
    "   \n",
    "    ## Scaling:\n",
    "    normalize(test_data)\n",
    "    \n",
    "    ## Predict:\n",
    "    predictions = model_LogisticReg.predict (test_data)\n",
    "    # It should create an array of predictions; we initialize it to the empty array for convenience\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "predicts = MyModel(fileName=testFileName)\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
